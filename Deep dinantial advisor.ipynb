{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74483142-5004-4bb0-bdfd-7f3f872874e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your monthly income:  45000\n",
      "Enter your savings till now:  5200\n",
      "Enter your loans:  2500\n",
      "Enter your EMI on loans:  3000\n",
      "Enter your monthly expenses:  10000\n",
      "Enter your health care costs:  3000\n",
      "Enter the number of dependents:  2\n",
      "Enter your insurance per month:  750\n",
      "Enter the period of investment in days (e.g., 365 for a year):  455\n",
      "Enter your risk preference (1 for high, 2 for medium, 3 for low):  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/1000], Loss: 0.0612\n",
      "Epoch [100/1000], Loss: 0.0002\n",
      "Epoch [200/1000], Loss: 0.0000\n",
      "Epoch [300/1000], Loss: 0.0000\n",
      "Epoch [400/1000], Loss: 0.0000\n",
      "Epoch [500/1000], Loss: 0.0000\n",
      "Epoch [600/1000], Loss: 0.0000\n",
      "Epoch [700/1000], Loss: 0.0000\n",
      "Epoch [800/1000], Loss: 0.0000\n",
      "Epoch [900/1000], Loss: 0.0000\n",
      "Encoded Parameters: [0.       0.       0.       0.       2.254443 0.      ]\n",
      "Decoded Parameters: [0.45  0.52  0.25  0.3   0.1   0.3   0.2   0.75  0.455 0.2  ]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "# Define the autoencoder class\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_size, encoding_size):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, encoding_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoding_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, input_size),\n",
    "            nn.Sigmoid()  # Sigmoid for reconstruction\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "def get_user_input():\n",
    "    monthly_income = float(input(\"Enter your monthly income: \"))\n",
    "    savings_till_now = float(input(\"Enter your savings till now: \"))\n",
    "    loans = float(input(\"Enter your loans: \"))\n",
    "    emi_on_loans = float(input(\"Enter your EMI on loans: \"))\n",
    "    monthly_expenses = float(input(\"Enter your monthly expenses: \"))\n",
    "    health_care_costs = float(input(\"Enter your health care costs: \"))\n",
    "    num_dependents = int(input(\"Enter the number of dependents: \"))\n",
    "    insurance_per_month = float(input(\"Enter your insurance per month: \"))\n",
    "    period_of_investment = int(input(\"Enter the period of investment in days (e.g., 365 for a year): \"))\n",
    "    risk = int(input(\"Enter your risk preference (1 for high, 2 for medium, 3 for low): \"))\n",
    "\n",
    "    return [monthly_income, savings_till_now, loans, emi_on_loans, monthly_expenses, health_care_costs, num_dependents, insurance_per_month, period_of_investment, risk]\n",
    "\n",
    "def get_digit_count(number):\n",
    "    return len(str(number).split('.')[0])\n",
    "\n",
    "# Normalize user input       \n",
    "user_input = get_user_input()\n",
    "digit_counts = [get_digit_count(number) for number in user_input]\n",
    "normalized_user_input = [number / (10 ** digit_count) for number, digit_count in zip(user_input, digit_counts)]\n",
    "\n",
    "# Convert normalized user input to tensor\n",
    "input_parameters_tensor = torch.tensor(normalized_user_input, dtype=torch.float32)\n",
    "\n",
    "# Define parameters\n",
    "input_size = len(normalized_user_input)  # Number of input parameters\n",
    "encoding_size = 6  # Size to which we want to reduce the parameters\n",
    "\n",
    "# Initialize the autoencoder\n",
    "autoencoder = Autoencoder(input_size, encoding_size)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(autoencoder.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    reconstructed_parameters = autoencoder(input_parameters_tensor)\n",
    "\n",
    "    # Compute the loss\n",
    "    loss = criterion(reconstructed_parameters, input_parameters_tensor)\n",
    "\n",
    "    # Backpropagation\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch [{epoch}/{epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Print the reduced parameters\n",
    "encoded_parameters = autoencoder.encoder(input_parameters_tensor)\n",
    "print(\"Encoded Parameters:\", encoded_parameters.detach().numpy())\n",
    "\n",
    "# Retrieve original parameters using the encoded values\n",
    "decoded_parameters = autoencoder.decoder(encoded_parameters)\n",
    "print(\"Decoded Parameters:\", decoded_parameters.detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96346cfe-e3cf-4ece-a236-5c710d27500b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 4, 4, 4, 5, 4, 1, 3, 3, 1]\n"
     ]
    }
   ],
   "source": [
    "print(digit_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71d41d2-4cee-4374-acf2-49bdd68e89c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "+ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee3ce7a3-acd8-4806-8d77-e14518df5c13",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You need to specify either `text` or `text_target`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m         encoded_parameters_strings\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mstr\u001b[39m(parameter))\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Tokenize each parameter individually\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m tokenized_parameters \u001b[38;5;241m=\u001b[39m  tokenizer ()\n\u001b[0;32m     23\u001b[0m tokenized_parameters \u001b[38;5;241m=\u001b[39m tokenizer(encoded_parameters_strings, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m'\u001b[39m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Example: Classification head for investment strategy recommendation\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2797\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[1;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2795\u001b[0m all_kwargs\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[0;32m   2796\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou need to specify either `text` or `text_target`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2798\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2799\u001b[0m     \u001b[38;5;66;03m# The context manager will send the inputs as normal texts and not text_target, but we shouldn't change the\u001b[39;00m\n\u001b[0;32m   2800\u001b[0m     \u001b[38;5;66;03m# input mode in this case.\u001b[39;00m\n\u001b[0;32m   2801\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n",
      "\u001b[1;31mValueError\u001b[0m: You need to specify either `text` or `text_target`."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "# Replace 'bert-base-uncased' with your chosen model name (e.g., 'gpt2', 'roberta-base')\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Assuming encoded_parameters_list is a list of lists\n",
    "encoded_parameters_list = encoded_parameters.tolist()  # Convert tensor to list\n",
    "\n",
    "# Convert the inner lists to strings, handling floats appropriately\n",
    "encoded_parameters_strings = []\n",
    "for parameter in encoded_parameters_list:\n",
    "    if isinstance(parameter, list):\n",
    "        encoded_parameters_strings.append(' '.join(map(str, parameter)))\n",
    "    else:\n",
    "        encoded_parameters_strings.append(str(parameter))\n",
    "\n",
    "# Tokenize each parameter individually\n",
    "tokenized_parameters =  tokenizer ()\n",
    "tokenized_parameters = tokenizer(encoded_parameters_strings, padding='max_length', return_tensors='pt', truncation=True)\n",
    "\n",
    "# Example: Classification head for investment strategy recommendation\n",
    "class InvestmentClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(InvestmentClassifier, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.fc(x)\n",
    "        return output\n",
    "\n",
    "# Example usage (replace with your actual logic)\n",
    "classifier = InvestmentClassifier(model.config.hidden_size, 3)  # 3 classes (e.g., conservative, moderate, aggressive)\n",
    "# Pass input_ids to the pre-trained model\n",
    "outputs = model(**tokenized_parameters)\n",
    "last_hidden_state = outputs.last_hidden_state[:, 0, :]  # Take the first token's representation\n",
    "\n",
    "# Use the last hidden state for further processing\n",
    "if classifier is not None:\n",
    "    logits = classifier(last_hidden_state)  # Get class logits for classification\n",
    "    print(logits)  # Output the logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55c4ed79-c5c1-43fe-8ea4-9b2d503cd31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide 10 input values:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input 1:  1200\n",
      "Input 2:  256\n",
      "Input 3:  31000\n",
      "Input 4:  32000\n",
      "Input 5:  69000\n",
      "Input 6:  12586\n",
      "Input 7:  21265\n",
      "Input 8:  4520\n",
      "Input 9:  1236\n",
      "Input 10:  5630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 103441720.0000\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 99865120.0000\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 96288488.0000\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 92711856.0000\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 89135272.0000\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 85558704.0000\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 81982000.0000\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 78405352.0000\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 74828736.0000\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 71252048.0000\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 67675224.0000\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 64098392.0000\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 60521484.0000\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 56944504.0000\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 53367252.0000\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 49789960.0000\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 46212472.0000\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 42634720.0000\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 39056744.0000\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 35478488.0000\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 31900006.0000\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 28321130.0000\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 24741836.0000\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 21162236.0000\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 17582094.0000\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 14001520.0000\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 10420354.0000\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 6838659.0000\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 3256384.0000\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: -326576.0000\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: -3910332.7500\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: -7494758.5000\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: -11079903.0000\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: -14666046.0000\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: -18252980.0000\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: -21840882.0000\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: -25429740.0000\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: -29019660.0000\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: -32610656.0000\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: -36202748.0000\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: -39796104.0000\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: -43390652.0000\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: -46986508.0000\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: -50583672.0000\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: -54182296.0000\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: -57782356.0000\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: -61383928.0000\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: -64986984.0000\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: -68591752.0000\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: -72198032.0000\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: -75806120.0000\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: -79415848.0000\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: -83027632.0000\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: -86641144.0000\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: -90256688.0000\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: -93874096.0000\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: -97493656.0000\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: -101115192.0000\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: -104739088.0000\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: -108365056.0000\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: -111993280.0000\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: -115623856.0000\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: -119256752.0000\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: -122892184.0000\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: -126530000.0000\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: -130170352.0000\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: -133813392.0000\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: -137459008.0000\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: -141107408.0000\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: -144758448.0000\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: -148412368.0000\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: -152069136.0000\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: -155728816.0000\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: -159391488.0000\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: -163057168.0000\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: -166725968.0000\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: -170397824.0000\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: -174072928.0000\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: -177751264.0000\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: -181432848.0000\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: -185117856.0000\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: -188806272.0000\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: -192498144.0000\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: -196193536.0000\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: -199892400.0000\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: -203594976.0000\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: -207301200.0000\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: -211011168.0000\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: -214724896.0000\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: -218442464.0000\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: -222163872.0000\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: -225889248.0000\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: -229618592.0000\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: -233351968.0000\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: -237089456.0000\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: -240831072.0000\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: -244576864.0000\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: -248327008.0000\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: -252081440.0000\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: -255840160.0000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Encoded representation: [[57581.19      0.        0.        0.    30616.357]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Define the input size\n",
    "input_size = 10\n",
    "\n",
    "# Define the architecture\n",
    "encoding_dim = 5  # Size of the encoded representation\n",
    "\n",
    "# Input placeholder\n",
    "input_data = Input(shape=(input_size,))\n",
    "\n",
    "# Encoder\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_data)\n",
    "\n",
    "# Decoder\n",
    "decoded = Dense(input_size, activation='sigmoid')(encoded)\n",
    "\n",
    "# Autoencoder model\n",
    "autoencoder = Model(input_data, decoded)\n",
    "\n",
    "# Encoder model\n",
    "encoder = Model(input_data, encoded)\n",
    "\n",
    "# Compile the autoencoder\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# Input from the user\n",
    "print(\"Please provide 10 input values:\")\n",
    "user_input = []\n",
    "for i in range(input_size):\n",
    "    value = float(input(\"Input {}: \".format(i + 1)))\n",
    "    user_input.append(value)\n",
    "user_data = np.array(user_input).reshape(1, -1)\n",
    "\n",
    "# Train the autoencoder\n",
    "autoencoder.fit(user_data, user_data, epochs=100, batch_size=16, shuffle=True)\n",
    "\n",
    "# Use the encoder to get the encoded representation of the input\n",
    "encoded_data = encoder.predict(user_data)\n",
    "\n",
    "print(\"Encoded representation:\", encoded_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e05353f-4f1d-412b-83b6-00a3a5afba42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(encoded_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfdcfbbf-fc02-46b5-975e-8424b79a70ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide 10 input values between 0 and 1000000000:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input 1:  100002\n",
      "Input 2:  10003\n",
      "Input 3:  10008\n",
      "Input 4:  1002\n",
      "Input 5:  3\n",
      "Input 6:  11026\n",
      "Input 7:  21003\n",
      "Input 8:  2102\n",
      "Input 9:  2023\n",
      "Input 10:  2103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "Encoded representation: [[0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Define the input size\n",
    "input_size = 10\n",
    "\n",
    "# Define the architecture\n",
    "encoding_dim = 5  # Size of the encoded representation\n",
    "\n",
    "# Input placeholder\n",
    "input_data = Input(shape=(input_size,))\n",
    "\n",
    "# Encoder\n",
    "encoded = Dense(8, activation='relu')(input_data)\n",
    "encoded = Dense(encoding_dim, activation='relu')(encoded)\n",
    "\n",
    "# Decoder\n",
    "decoded = Dense(8, activation='relu')(encoded)\n",
    "decoded = Dense(input_size, activation='sigmoid')(decoded)\n",
    "\n",
    "# Autoencoder model\n",
    "autoencoder = Model(input_data, decoded)\n",
    "\n",
    "# Encoder model\n",
    "encoder = Model(input_data, encoded)\n",
    "\n",
    "# Compile the autoencoder\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Input from the user\n",
    "print(\"Please provide 10 input values between 0 and 1000000000:\")\n",
    "user_input = []\n",
    "for i in range(input_size):\n",
    "    value = float(input(\"Input {}: \".format(i + 1)))\n",
    "    user_input.append(value)\n",
    "\n",
    "# Normalize the input data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "user_data = np.array(user_input).reshape(1, -1)\n",
    "user_data_normalized = scaler.fit_transform(user_data)\n",
    "\n",
    "# Train the autoencoder\n",
    "autoencoder.fit(user_data_normalized, user_data_normalized, epochs=1000, batch_size=16, shuffle=True, verbose=0)\n",
    "\n",
    "# Use the encoder to get the encoded representation of the input\n",
    "encoded_data = encoder.predict(user_data_normalized)\n",
    "\n",
    "print(\"Encoded representation:\", encoded_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94e9a3fc-0790-4b2d-8e24-2aca73b9c9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.4723 - val_loss: 0.2674\n",
      "Epoch 2/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2590 - val_loss: 0.2342\n",
      "Epoch 3/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2307 - val_loss: 0.2160\n",
      "Epoch 4/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2143 - val_loss: 0.2058\n",
      "Epoch 5/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2065 - val_loss: 0.2020\n",
      "Epoch 6/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2030 - val_loss: 0.1997\n",
      "Epoch 7/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2011 - val_loss: 0.1980\n",
      "Epoch 8/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1988 - val_loss: 0.1966\n",
      "Epoch 9/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1975 - val_loss: 0.1956\n",
      "Epoch 10/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1963 - val_loss: 0.1946\n",
      "Epoch 11/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1955 - val_loss: 0.1937\n",
      "Epoch 12/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1948 - val_loss: 0.1930\n",
      "Epoch 13/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1942 - val_loss: 0.1925\n",
      "Epoch 14/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1937 - val_loss: 0.1918\n",
      "Epoch 15/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1932 - val_loss: 0.1913\n",
      "Epoch 16/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1921 - val_loss: 0.1909\n",
      "Epoch 17/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1921 - val_loss: 0.1905\n",
      "Epoch 18/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1916 - val_loss: 0.1901\n",
      "Epoch 19/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1912 - val_loss: 0.1898\n",
      "Epoch 20/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1908 - val_loss: 0.1896\n",
      "Epoch 21/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1908 - val_loss: 0.1893\n",
      "Epoch 22/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1903 - val_loss: 0.1891\n",
      "Epoch 23/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1903 - val_loss: 0.1890\n",
      "Epoch 24/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1906 - val_loss: 0.1888\n",
      "Epoch 25/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1900 - val_loss: 0.1887\n",
      "Epoch 26/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1895 - val_loss: 0.1885\n",
      "Epoch 27/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1902 - val_loss: 0.1885\n",
      "Epoch 28/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1899 - val_loss: 0.1884\n",
      "Epoch 29/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1896 - val_loss: 0.1883\n",
      "Epoch 30/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1897 - val_loss: 0.1882\n",
      "Epoch 31/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1894 - val_loss: 0.1882\n",
      "Epoch 32/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1896 - val_loss: 0.1881\n",
      "Epoch 33/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1891 - val_loss: 0.1881\n",
      "Epoch 34/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1897 - val_loss: 0.1879\n",
      "Epoch 35/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1891 - val_loss: 0.1880\n",
      "Epoch 36/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1890 - val_loss: 0.1879\n",
      "Epoch 37/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1895 - val_loss: 0.1878\n",
      "Epoch 38/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1892 - val_loss: 0.1878\n",
      "Epoch 39/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1890 - val_loss: 0.1878\n",
      "Epoch 40/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1891 - val_loss: 0.1877\n",
      "Epoch 41/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1887 - val_loss: 0.1877\n",
      "Epoch 42/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1890 - val_loss: 0.1876\n",
      "Epoch 43/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1892 - val_loss: 0.1876\n",
      "Epoch 44/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1888 - val_loss: 0.1876\n",
      "Epoch 45/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1889 - val_loss: 0.1876\n",
      "Epoch 46/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1890 - val_loss: 0.1876\n",
      "Epoch 47/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1889 - val_loss: 0.1876\n",
      "Epoch 48/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1885 - val_loss: 0.1876\n",
      "Epoch 49/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1888 - val_loss: 0.1875\n",
      "Epoch 50/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1887 - val_loss: 0.1876\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x400 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter input 1 (0-999999999):  1033\n",
      "Enter input 2 (0-999999999):  1024\n",
      "Enter input 3 (0-999999999):  3021\n",
      "Enter input 4 (0-999999999):  5230\n",
      "Enter input 5 (0-999999999):  1563\n",
      "Enter input 6 (0-999999999):  3215\n",
      "Enter input 7 (0-999999999):  22223\n",
      "Enter input 8 (0-999999999):  6542\n",
      "Enter input 9 (0-999999999):  222\n",
      "Enter input 10 (0-999999999):  3\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node functional_21_1/dense_10_1/Relu defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\asyncio\\windows_events.py\", line 321, in run_forever\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3051, in run_cell\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3106, in _run_cell\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3311, in run_cell_async\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3493, in run_ast_nodes\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3553, in run_code\n\n  File \"C:\\Users\\bharg\\AppData\\Local\\Temp\\ipykernel_5576\\231749788.py\", line 79, in <module>\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 118, in error_handler\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 513, in predict\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 212, in one_step_on_data_distributed\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 201, in one_step_on_data\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 93, in predict_step\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 118, in error_handler\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 816, in __call__\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 118, in error_handler\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 42, in __call__\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 157, in error_handler\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 188, in call\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\function.py\", line 153, in _run_through_graph\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 572, in call\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 118, in error_handler\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 816, in __call__\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 118, in error_handler\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 42, in __call__\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 157, in error_handler\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py\", line 141, in call\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\keras\\src\\activations\\activations.py\", line 47, in relu\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\keras\\src\\activations\\activations.py\", line 99, in static_call\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py\", line 16, in relu\n\nMatrix size-incompatible: In[0]: [1,10], In[1]: [784,5]\n\t [[{{node functional_21_1/dense_10_1/Relu}}]] [Op:__inference_one_step_on_data_distributed_67389]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 79\u001b[0m\n\u001b[0;32m     76\u001b[0m scaled_inputs \u001b[38;5;241m=\u001b[39m scale_to_range(user_inputs, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m999999999\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m# Encode the inputs\u001b[39;00m\n\u001b[1;32m---> 79\u001b[0m encoded_inputs \u001b[38;5;241m=\u001b[39m encoder\u001b[38;5;241m.\u001b[39mpredict(np\u001b[38;5;241m.\u001b[39marray([scaled_inputs]))\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEncoded Parameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28mprint\u001b[39m(encoded_inputs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:123\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node functional_21_1/dense_10_1/Relu defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\asyncio\\windows_events.py\", line 321, in run_forever\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3051, in run_cell\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3106, in _run_cell\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3311, in run_cell_async\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3493, in run_ast_nodes\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3553, in run_code\n\n  File \"C:\\Users\\bharg\\AppData\\Local\\Temp\\ipykernel_5576\\231749788.py\", line 79, in <module>\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 118, in error_handler\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 513, in predict\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 212, in one_step_on_data_distributed\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 201, in one_step_on_data\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 93, in predict_step\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 118, in error_handler\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 816, in __call__\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 118, in error_handler\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 42, in __call__\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 157, in error_handler\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 188, in call\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\function.py\", line 153, in _run_through_graph\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 572, in call\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 118, in error_handler\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 816, in __call__\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 118, in error_handler\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 42, in __call__\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 157, in error_handler\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py\", line 141, in call\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\keras\\src\\activations\\activations.py\", line 47, in relu\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\keras\\src\\activations\\activations.py\", line 99, in static_call\n\n  File \"C:\\Users\\bharg\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py\", line 16, in relu\n\nMatrix size-incompatible: In[0]: [1,10], In[1]: [784,5]\n\t [[{{node functional_21_1/dense_10_1/Relu}}]] [Op:__inference_one_step_on_data_distributed_67389]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "(x_train, _), (x_test, _) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "\n",
    "# Define the autoencoder model\n",
    "encoding_dim = 5\n",
    "input_img = tf.keras.Input(shape=(784,))\n",
    "encoded = tf.keras.layers.Dense(encoding_dim, activation='relu')(input_img)\n",
    "decoded = tf.keras.layers.Dense(784, activation='sigmoid')(encoded)\n",
    "\n",
    "autoencoder = tf.keras.Model(input_img, decoded)\n",
    "\n",
    "# Create separate encoder model\n",
    "encoder = tf.keras.Model(input_img, encoded)\n",
    "\n",
    "# Create separate decoder model\n",
    "encoded_input = tf.keras.Input(shape=(encoding_dim,))\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "decoder = tf.keras.Model(encoded_input, decoder_layer(encoded_input))\n",
    "\n",
    "# Compile the model\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# Train the autoencoder\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))\n",
    "\n",
    "# Encode and decode some digits\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "# Plot the reconstructed digits\n",
    "n = 10  \n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "\n",
    "# Convert 10 inputs to encoded parameters in the range [0, 999999999]\n",
    "def scale_to_range(inputs, min_val, max_val, new_min, new_max):\n",
    "    scaled_values = []\n",
    "    for val in inputs:\n",
    "        scaled_val = ((val - min_val) / (max_val - min_val)) * (new_max - new_min) + new_min\n",
    "        scaled_values.append(scaled_val)\n",
    "    return scaled_values\n",
    "\n",
    "# Take 10 inputs from the user\n",
    "user_inputs = []\n",
    "for i in range(10):\n",
    "    user_input = int(input(f\"Enter input {i + 1} (0-999999999): \"))\n",
    "    user_inputs.append(user_input)\n",
    "\n",
    "# Scale the inputs to fit the model range\n",
    "scaled_inputs = scale_to_range(user_inputs, 0, 999999999, 0, 1)\n",
    "\n",
    "# Encode the inputs\n",
    "encoded_inputs = encoder.predict(np.array([scaled_inputs]))\n",
    "\n",
    "print(\"\\nEncoded Parameters:\")\n",
    "print(encoded_inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf1e61fa-0dfd-40d5-9adc-6ae4865ecbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your annual income:  2500000\n",
      "Enter the number of loans you have:  2\n",
      "Enter the principal amount for loan 1:  200000\n",
      "Enter the interest rate for loan 1 (%):  3\n",
      "Enter the principal amount for loan 2:  60000\n",
      "Enter the interest rate for loan 2 (%):  2\n",
      "Enter your total savings:  600000\n",
      "Enter the number of dependents:  2\n",
      "Enter your monthly expenses:  62000\n",
      "Enter your desired investment duration (in years):  3\n",
      "Enter your risk tolerance (low/medium/high):  low\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteDisconnected\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:791\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    790\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 791\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    792\u001b[0m     conn,\n\u001b[0;32m    793\u001b[0m     method,\n\u001b[0;32m    794\u001b[0m     url,\n\u001b[0;32m    795\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    796\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    797\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    798\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    799\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    800\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    801\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    802\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    803\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    804\u001b[0m )\n\u001b[0;32m    806\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:537\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 537\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:461\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 461\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:1378\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1378\u001b[0m     response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[0;32m   1379\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:287\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m line:\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Presumably, the server closed the connection before\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# sending a valid response.\u001b[39;00m\n\u001b[1;32m--> 287\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RemoteDisconnected(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRemote end closed connection without\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    288\u001b[0m                              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m response\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mRemoteDisconnected\u001b[0m: Remote end closed connection without response",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mProtocolError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    487\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    488\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    489\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[0;32m    490\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    491\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    492\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    493\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    494\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    495\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[0;32m    496\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    497\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    498\u001b[0m     )\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:845\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    843\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[1;32m--> 845\u001b[0m retries \u001b[38;5;241m=\u001b[39m retries\u001b[38;5;241m.\u001b[39mincrement(\n\u001b[0;32m    846\u001b[0m     method, url, error\u001b[38;5;241m=\u001b[39mnew_e, _pool\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, _stacktrace\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    847\u001b[0m )\n\u001b[0;32m    848\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py:470\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_method_retryable(method):\n\u001b[1;32m--> 470\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m reraise(\u001b[38;5;28mtype\u001b[39m(error), error, _stacktrace)\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\util\\util.py:38\u001b[0m, in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m value\u001b[38;5;241m.\u001b[39m__traceback__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tb:\n\u001b[1;32m---> 38\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m value\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:791\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    790\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 791\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    792\u001b[0m     conn,\n\u001b[0;32m    793\u001b[0m     method,\n\u001b[0;32m    794\u001b[0m     url,\n\u001b[0;32m    795\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    796\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    797\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    798\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    799\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    800\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    801\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    802\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    803\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    804\u001b[0m )\n\u001b[0;32m    806\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:537\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 537\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:461\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 461\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:1378\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1378\u001b[0m     response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[0;32m   1379\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:287\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m line:\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Presumably, the server closed the connection before\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# sending a valid response.\u001b[39;00m\n\u001b[1;32m--> 287\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RemoteDisconnected(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRemote end closed connection without\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    288\u001b[0m                              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m response\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mProtocolError\u001b[0m: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 107\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    106\u001b[0m     user_input \u001b[38;5;241m=\u001b[39m get_user_input()\n\u001b[1;32m--> 107\u001b[0m     financial_data \u001b[38;5;241m=\u001b[39m scrape_financial_data()\n\u001b[0;32m    108\u001b[0m     recommendations \u001b[38;5;241m=\u001b[39m generate_recommendations(user_input, financial_data)\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTop Investment Recommendations:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 68\u001b[0m, in \u001b[0;36mscrape_financial_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscrape_financial_data\u001b[39m():\n\u001b[0;32m     67\u001b[0m     url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.nseindia.com/market-data/live-equity-market\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 68\u001b[0m     response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[0;32m     69\u001b[0m     soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(response\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;66;03m# Extract stock data\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:501\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    487\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    488\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    497\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    498\u001b[0m     )\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    503\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MaxRetryError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    504\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, ConnectTimeoutError):\n\u001b[0;32m    505\u001b[0m         \u001b[38;5;66;03m# TODO: Remove this in 3.0.0: see #2811\u001b[39;00m\n",
      "\u001b[1;31mConnectionError\u001b[0m: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, LayerNormalization, MultiHeadAttention, Dropout\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# User Input Handling\n",
    "def get_user_input():\n",
    "    income = float(input(\"Enter your annual income: \"))\n",
    "    loan_details = {}\n",
    "    num_loans = int(input(\"Enter the number of loans you have: \"))\n",
    "    for i in range(num_loans):\n",
    "        loan_principal = float(input(f\"Enter the principal amount for loan {i+1}: \"))\n",
    "        loan_interest = float(input(f\"Enter the interest rate for loan {i+1} (%): \"))\n",
    "        loan_details[f\"loan_{i+1}\"] = (loan_principal, loan_interest / 100)\n",
    "    total_savings = float(input(\"Enter your total savings: \"))\n",
    "    num_dependents = int(input(\"Enter the number of dependents: \"))\n",
    "    monthly_expenses = float(input(\"Enter your monthly expenses: \"))\n",
    "    investment_duration = int(input(\"Enter your desired investment duration (in years): \"))\n",
    "    risk_tolerance = input(\"Enter your risk tolerance (low/medium/high): \")\n",
    "    return income, loan_details, total_savings, num_dependents, monthly_expenses, investment_duration, risk_tolerance\n",
    "\n",
    "# Feature Engineering\n",
    "def preprocess_data(user_input):\n",
    "    income, loan_details, total_savings, num_dependents, monthly_expenses, investment_duration, risk_tolerance = user_input\n",
    "    features = [income, total_savings, num_dependents, monthly_expenses, investment_duration]\n",
    "    for loan in loan_details.values():\n",
    "        features.extend(loan)\n",
    "    if risk_tolerance == \"low\":\n",
    "        risk_score = 0.2\n",
    "    elif risk_tolerance == \"medium\":\n",
    "        risk_score = 0.5\n",
    "    else:\n",
    "        risk_score = 0.8\n",
    "    features.append(risk_score)\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_features = scaler.fit_transform([features])\n",
    "    return scaled_features\n",
    "\n",
    "# Transformer Model for Time Series Data\n",
    "def build_transformer_model(input_dim, output_dim):\n",
    "    inputs = Input(shape=(None, input_dim))\n",
    "    encoder_layer = TransformerEncoder(MultiHeadAttention(num_heads=8, key_dim=64), norm_epsilon=1e-6, dropout=0.1)\n",
    "    x = encoder_layer(inputs)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    decoder_layer = TransformerDecoder(MultiHeadAttention(num_heads=8, key_dim=64), norm_epsilon=1e-6, dropout=0.1)\n",
    "    x = decoder_layer(x)\n",
    "    x = LayerNormalization()(x)\n",
    "    outputs = Dense(output_dim, activation='linear')(x)\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# Web Scraping for Financial Data\n",
    "def scrape_financial_data():\n",
    "    url = \"https://www.nseindia.com/market-data/live-equity-market\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Extract stock data\n",
    "    stock_data = []\n",
    "    table = soup.find('table', {'id': 'data_table_Market'})\n",
    "    if table:\n",
    "        rows = table.find_all('tr')\n",
    "        for row in rows[1:]:\n",
    "            cols = row.find_all('td')\n",
    "            if cols:\n",
    "                stock_name = cols[0].text.strip()\n",
    "                stock_price = float(cols[3].text.replace(',', ''))\n",
    "                stock_data.append({'name': stock_name, 'price': stock_price})\n",
    "\n",
    "    return stock_data\n",
    "\n",
    "# Recommendation Generation\n",
    "def generate_recommendations(user_input, financial_data):\n",
    "    scaled_features = preprocess_data(user_input)\n",
    "\n",
    "    # Prepare financial data for Transformer model\n",
    "    stock_prices = [data['price'] for data in financial_data]\n",
    "    input_sequence = np.array(stock_prices[-60:]).reshape(1, 60, 1)  # Using last 60 days' data\n",
    "\n",
    "    transformer_model = build_transformer_model(input_dim=1, output_dim=1)\n",
    "    predictions = transformer_model.predict(input_sequence)\n",
    "\n",
    "    # Rank and select the top recommendations\n",
    "    stock_recommendations = sorted(financial_data, key=lambda x: x['price'], reverse=True)[:10]\n",
    "    top_recommendations = [f\"{recommendation['name']} (Price: {recommendation['price']})\" for recommendation in stock_recommendations]\n",
    "\n",
    "    return top_recommendations\n",
    "\n",
    "# Main Loop\n",
    "if __name__ == \"__main__\":\n",
    "    user_input = get_user_input()\n",
    "    financial_data = scrape_financial_data()\n",
    "    recommendations = generate_recommendations(user_input, financial_data)\n",
    "    print(\"Top Investment Recommendations:\")\n",
    "    for i, recommendation in enumerate(recommendations, start=1):\n",
    "        print(f\"{i}. {recommendation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dab61e48-aca3-4cc1-b518-956df576eae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your annual income:  230000\n",
      "Enter the number of loans you have:  2\n",
      "Enter the principal amount for loan 1:  1230\n",
      "Enter the interest rate for loan 1 (%):  3\n",
      "Enter the principal amount for loan 2:  12530\n",
      "Enter the interest rate for loan 2 (%):  21\n",
      "Enter your total savings:  2155\n",
      "Enter the number of dependents:  4\n",
      "Enter your monthly expenses:  1556\n",
      "Enter your desired investment duration (in years):  13\n",
      "Enter your risk tolerance (low/medium/high):  low\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteDisconnected\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:791\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    790\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 791\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    792\u001b[0m     conn,\n\u001b[0;32m    793\u001b[0m     method,\n\u001b[0;32m    794\u001b[0m     url,\n\u001b[0;32m    795\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    796\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    797\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    798\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    799\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    800\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    801\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    802\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    803\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    804\u001b[0m )\n\u001b[0;32m    806\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:537\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 537\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:461\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 461\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:1378\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1378\u001b[0m     response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[0;32m   1379\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:287\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m line:\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Presumably, the server closed the connection before\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# sending a valid response.\u001b[39;00m\n\u001b[1;32m--> 287\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RemoteDisconnected(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRemote end closed connection without\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    288\u001b[0m                              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m response\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mRemoteDisconnected\u001b[0m: Remote end closed connection without response",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mProtocolError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    487\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    488\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    489\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[0;32m    490\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    491\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    492\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    493\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    494\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    495\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[0;32m    496\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    497\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    498\u001b[0m     )\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:845\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    843\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[1;32m--> 845\u001b[0m retries \u001b[38;5;241m=\u001b[39m retries\u001b[38;5;241m.\u001b[39mincrement(\n\u001b[0;32m    846\u001b[0m     method, url, error\u001b[38;5;241m=\u001b[39mnew_e, _pool\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, _stacktrace\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    847\u001b[0m )\n\u001b[0;32m    848\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py:470\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_method_retryable(method):\n\u001b[1;32m--> 470\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m reraise(\u001b[38;5;28mtype\u001b[39m(error), error, _stacktrace)\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\util\\util.py:38\u001b[0m, in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m value\u001b[38;5;241m.\u001b[39m__traceback__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tb:\n\u001b[1;32m---> 38\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m value\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:791\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    790\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 791\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    792\u001b[0m     conn,\n\u001b[0;32m    793\u001b[0m     method,\n\u001b[0;32m    794\u001b[0m     url,\n\u001b[0;32m    795\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    796\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    797\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    798\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    799\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    800\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    801\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    802\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    803\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    804\u001b[0m )\n\u001b[0;32m    806\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:537\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 537\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:461\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 461\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:1378\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1378\u001b[0m     response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[0;32m   1379\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:287\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m line:\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Presumably, the server closed the connection before\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# sending a valid response.\u001b[39;00m\n\u001b[1;32m--> 287\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RemoteDisconnected(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRemote end closed connection without\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    288\u001b[0m                              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m response\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mProtocolError\u001b[0m: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 97\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     96\u001b[0m     user_input \u001b[38;5;241m=\u001b[39m get_user_input()\n\u001b[1;32m---> 97\u001b[0m     financial_data \u001b[38;5;241m=\u001b[39m scrape_financial_data()\n\u001b[0;32m     98\u001b[0m     recommendations \u001b[38;5;241m=\u001b[39m generate_recommendations(user_input, financial_data)\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTop Investment Recommendations:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 60\u001b[0m, in \u001b[0;36mscrape_financial_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscrape_financial_data\u001b[39m():\n\u001b[0;32m     59\u001b[0m     url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.nseindia.com/market-data/live-equity-market\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 60\u001b[0m     response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[0;32m     61\u001b[0m     soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(response\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;66;03m# Extract stock data\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:501\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    487\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    488\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    497\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    498\u001b[0m     )\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    503\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MaxRetryError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    504\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, ConnectTimeoutError):\n\u001b[0;32m    505\u001b[0m         \u001b[38;5;66;03m# TODO: Remove this in 3.0.0: see #2811\u001b[39;00m\n",
      "\u001b[1;31mConnectionError\u001b[0m: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, LayerNormalization, MultiHeadAttention, Dropout\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# User Input Handling\n",
    "def get_user_input():\n",
    "    income = float(input(\"Enter your annual income: \"))\n",
    "    loan_details = {}\n",
    "    num_loans = int(input(\"Enter the number of loans you have: \"))\n",
    "    for i in range(num_loans):\n",
    "        loan_principal = float(input(f\"Enter the principal amount for loan {i+1}: \"))\n",
    "        loan_interest = float(input(f\"Enter the interest rate for loan {i+1} (%): \"))\n",
    "        loan_details[f\"loan_{i+1}\"] = (loan_principal, loan_interest / 100)\n",
    "    total_savings = float(input(\"Enter your total savings: \"))\n",
    "    num_dependents = int(input(\"Enter the number of dependents: \"))\n",
    "    monthly_expenses = float(input(\"Enter your monthly expenses: \"))\n",
    "    investment_duration = int(input(\"Enter your desired investment duration (in years): \"))\n",
    "    risk_tolerance = input(\"Enter your risk tolerance (low/medium/high): \")\n",
    "    return income, loan_details, total_savings, num_dependents, monthly_expenses, investment_duration, risk_tolerance\n",
    "\n",
    "# Feature Engineering\n",
    "def preprocess_data(user_input):\n",
    "    income, loan_details, total_savings, num_dependents, monthly_expenses, investment_duration, risk_tolerance = user_input\n",
    "    features = [income, total_savings, num_dependents, monthly_expenses, investment_duration]\n",
    "    for loan in loan_details.values():\n",
    "        features.extend(loan)\n",
    "    if risk_tolerance == \"low\":\n",
    "        risk_score = 0.2\n",
    "    elif risk_tolerance == \"medium\":\n",
    "        risk_score = 0.5\n",
    "    else:\n",
    "        risk_score = 0.8\n",
    "    features.append(risk_score)\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_features = scaler.fit_transform([features])\n",
    "    return scaled_features\n",
    "\n",
    "# Transformer Model for Time Series Data\n",
    "def build_transformer_model(input_dim, output_dim):\n",
    "    inputs = Input(shape=(None, input_dim))\n",
    "    encoder_layer = TransformerEncoder(MultiHeadAttention(num_heads=8, key_dim=64), norm_epsilon=1e-6, dropout=0.1)\n",
    "    x = encoder_layer(inputs)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    decoder_layer = TransformerDecoder(MultiHeadAttention(num_heads=8, key_dim=64), norm_epsilon=1e-6, dropout=0.1)\n",
    "    x = decoder_layer(x)\n",
    "    x = LayerNormalization()(x)\n",
    "    outputs = Dense(output_dim, activation='linear')(x)\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# Web Scraping for Financial Data\n",
    "def scrape_financial_data():\n",
    "    url = \"https://www.nseindia.com/market-data/live-equity-market\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Extract stock data\n",
    "    stock_data = []\n",
    "    table = soup.find('table', {'id': 'data_table_Market'})\n",
    "    if table:\n",
    "        rows = table.find_all('tr')\n",
    "        for row in rows[1:]:\n",
    "            cols = row.find_all('td')\n",
    "            if cols:\n",
    "                stock_name = cols[0].text.strip()\n",
    "                stock_price = float(cols[3].text.replace(',', ''))\n",
    "                stock_data.append({'name': stock_name, 'price': stock_price})\n",
    "\n",
    "    return stock_data\n",
    "\n",
    "# Recommendation Generation\n",
    "def generate_recommendations(user_input, financial_data):\n",
    "    scaled_features = preprocess_data(user_input)\n",
    "\n",
    "    # Prepare financial data for Transformer model\n",
    "    stock_prices = [data['price'] for data in financial_data]\n",
    "    input_sequence = np.array(stock_prices[-60:]).reshape(1, 60, 1)  # Using last 60 days' data\n",
    "\n",
    "    transformer_model = build_transformer_model(input_dim=1, output_dim=1)\n",
    "    predictions = transformer_model.predict(input_sequence)\n",
    "\n",
    "    # Rank and select the top recommendations\n",
    "    stock_recommendations = sorted(financial_data, key=lambda x: x['price'], reverse=True)[:10]\n",
    "    top_recommendations = [f\"{recommendation['name']} (Price: {recommendation['price']})\" for recommendation in stock_recommendations]\n",
    "\n",
    "    return top_recommendations\n",
    "\n",
    "# Main Loop\n",
    "if __name__ == \"__main__\":\n",
    "    user_input = get_user_input()\n",
    "    financial_data = scrape_financial_data()\n",
    "    recommendations = generate_recommendations(user_input, financial_data)\n",
    "    print(\"Top Investment Recommendations:\")\n",
    "    for i, recommendation in enumerate(recommendations, start=1):\n",
    "        print(f\"{i}. {recommendation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39f8c37c-982a-4e90-9a0d-2527ffef1bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras._tf_keras.keras.layers' has no attribute 'TransformerEncoder'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 100\u001b[0m\n\u001b[0;32m     97\u001b[0m train_data, val_data \u001b[38;5;241m=\u001b[39m split_data(scaled_data)\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# Train the Transformer model\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m trained_model \u001b[38;5;241m=\u001b[39m train_transformer_model(train_data, val_data)\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# Save the trained model\u001b[39;00m\n\u001b[0;32m    103\u001b[0m trained_model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransformer_model.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 64\u001b[0m, in \u001b[0;36mtrain_transformer_model\u001b[1;34m(train_data, val_data)\u001b[0m\n\u001b[0;32m     61\u001b[0m input_dim \u001b[38;5;241m=\u001b[39m train_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     62\u001b[0m output_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 64\u001b[0m transformer_model \u001b[38;5;241m=\u001b[39m TransformerModel(input_dim, output_dim)\n\u001b[0;32m     66\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m     67\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mMeanSquaredError()\n",
      "Cell \u001b[1;32mIn[3], line 37\u001b[0m, in \u001b[0;36mTransformerModel.__init__\u001b[1;34m(self, input_dim, output_dim, num_heads, ff_dim, dropout_rate)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mff_dim \u001b[38;5;241m=\u001b[39m ff_dim\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout_rate \u001b[38;5;241m=\u001b[39m dropout_rate\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder_layer \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mTransformerEncoder(\n\u001b[0;32m     38\u001b[0m     layers\u001b[38;5;241m.\u001b[39mTransformerEncoderLayer(\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mff_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, dropout_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout_rate\n\u001b[0;32m     40\u001b[0m     ),\n\u001b[0;32m     41\u001b[0m     norm_layer\u001b[38;5;241m=\u001b[39mlayers\u001b[38;5;241m.\u001b[39mLayerNormalization(),\n\u001b[0;32m     42\u001b[0m )\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder_layer \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mTransformerDecoder(\n\u001b[0;32m     45\u001b[0m     layers\u001b[38;5;241m.\u001b[39mTransformerDecoderLayer(\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mff_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, dropout_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout_rate\n\u001b[0;32m     47\u001b[0m     ),\n\u001b[0;32m     48\u001b[0m     norm_layer\u001b[38;5;241m=\u001b[39mlayers\u001b[38;5;241m.\u001b[39mLayerNormalization(),\n\u001b[0;32m     49\u001b[0m )\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_layer \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dim)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'keras._tf_keras.keras.layers' has no attribute 'TransformerEncoder'"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Function to fetch historical stock data\n",
    "def fetch_historical_data(stock_symbol, start_date, end_date):\n",
    "    stock_data = yf.download(stock_symbol, start=start_date, end=end_date)\n",
    "    return stock_data\n",
    "\n",
    "# Function to preprocess the stock data\n",
    "def preprocess_data(stock_data):\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_data = scaler.fit_transform(stock_data)\n",
    "    return scaled_data\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "def split_data(scaled_data, split_ratio=0.8):\n",
    "    split_index = int(len(scaled_data) * split_ratio)\n",
    "    train_data = scaled_data[:split_index]\n",
    "    val_data = scaled_data[split_index:]\n",
    "    return train_data, val_data\n",
    "\n",
    "# Transformer Model for Time Series Data\n",
    "class TransformerModel(keras.Model):\n",
    "    def __init__(self, input_dim, output_dim, num_heads=8, ff_dim=512, dropout_rate=0.1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.ff_dim = ff_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        self.encoder_layer = layers.TransformerEncoder(\n",
    "            layers.TransformerEncoderLayer(\n",
    "                self.ff_dim, self.num_heads, dropout_rate=self.dropout_rate\n",
    "            ),\n",
    "            norm_layer=layers.LayerNormalization(),\n",
    "        )\n",
    "\n",
    "        self.decoder_layer = layers.TransformerDecoder(\n",
    "            layers.TransformerDecoderLayer(\n",
    "                self.ff_dim, self.num_heads, dropout_rate=self.dropout_rate\n",
    "            ),\n",
    "            norm_layer=layers.LayerNormalization(),\n",
    "        )\n",
    "\n",
    "        self.output_layer = layers.Dense(self.output_dim)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        encoder_output = self.encoder_layer(inputs, training=training)\n",
    "        decoder_output = self.decoder_layer(encoder_output, encoder_output, training=training)\n",
    "        output = self.output_layer(decoder_output)\n",
    "        return output\n",
    "\n",
    "# Train the Transformer model\n",
    "def train_transformer_model(train_data, val_data):\n",
    "    input_dim = train_data.shape[-1]\n",
    "    output_dim = 1\n",
    "\n",
    "    transformer_model = TransformerModel(input_dim, output_dim)\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "    loss_fn = keras.losses.MeanSquaredError()\n",
    "\n",
    "    transformer_model.compile(optimizer=optimizer, loss=loss_fn)\n",
    "\n",
    "    callbacks = [\n",
    "        keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    ]\n",
    "\n",
    "    transformer_model.fit(\n",
    "        train_data, train_data[:, 1:, :],\n",
    "        validation_data=(val_data, val_data[:, 1:, :]),\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    return transformer_model\n",
    "\n",
    "# Main function\n",
    "if __name__ == \"__main__\":\n",
    "    # Fetch historical stock data for a specific stock or index (e.g., Nifty 50)\n",
    "    start_date = \"2018-01-01\"\n",
    "    end_date = \"2023-05-10\"\n",
    "    stock_symbol = \"^NSEI\"  # Nifty 50 index\n",
    "    stock_data = fetch_historical_data(stock_symbol, start_date, end_date)\n",
    "\n",
    "    # Preprocess the stock data\n",
    "    scaled_data = preprocess_data(stock_data)\n",
    "\n",
    "    # Split the data into training and validation sets\n",
    "    train_data, val_data = split_data(scaled_data)\n",
    "\n",
    "    # Train the Transformer model\n",
    "    trained_model = train_transformer_model(train_data, val_data)\n",
    "\n",
    "    # Save the trained model\n",
    "    trained_model.save(\"transformer_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f7dcf6a-3fa3-4d19-847c-0b05a8753e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-nlp\n",
      "  Obtaining dependency information for keras-nlp from https://files.pythonhosted.org/packages/3f/7b/cddb18e4c1f7729bf8cbeb51cc3ab26dedb377a91bc2d059461adf5e2d48/keras_nlp-0.11.1-py3-none-any.whl.metadata\n",
      "  Downloading keras_nlp-0.11.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting keras-core (from keras-nlp)\n",
      "  Obtaining dependency information for keras-core from https://files.pythonhosted.org/packages/95/f7/b8dcff937ea64f822f0d3fe8c6010793406b82d14467cd0e9eecea458a40/keras_core-0.1.7-py3-none-any.whl.metadata\n",
      "  Downloading keras_core-0.1.7-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: absl-py in c:\\users\\bharg\\anaconda3\\lib\\site-packages (from keras-nlp) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\bharg\\anaconda3\\lib\\site-packages (from keras-nlp) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\bharg\\anaconda3\\lib\\site-packages (from keras-nlp) (23.1)\n",
      "Requirement already satisfied: regex in c:\\users\\bharg\\anaconda3\\lib\\site-packages (from keras-nlp) (2023.10.3)\n",
      "Requirement already satisfied: rich in c:\\users\\bharg\\anaconda3\\lib\\site-packages (from keras-nlp) (13.3.5)\n",
      "Requirement already satisfied: dm-tree in c:\\users\\bharg\\anaconda3\\lib\\site-packages (from keras-nlp) (0.1.8)\n",
      "Collecting kagglehub (from keras-nlp)\n",
      "  Obtaining dependency information for kagglehub from https://files.pythonhosted.org/packages/bb/d5/f650605faef0c87df34db89dd548d1b529f7a09852df8a8e767c396e4e0c/kagglehub-0.2.5-py3-none-any.whl.metadata\n",
      "  Downloading kagglehub-0.2.5-py3-none-any.whl.metadata (18 kB)\n",
      "INFO: pip is looking at multiple versions of keras-nlp to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting keras-nlp\n",
      "  Obtaining dependency information for keras-nlp from https://files.pythonhosted.org/packages/e4/db/87bc5695a8089241952ee6b2d68cc9c09e67604a1360cb9606a06201012b/keras_nlp-0.11.0-py3-none-any.whl.metadata\n",
      "  Downloading keras_nlp-0.11.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Obtaining dependency information for keras-nlp from https://files.pythonhosted.org/packages/73/7c/5888e8840916899e557545de00743c1eac406c5978ce58f11eaa69401f1b/keras_nlp-0.10.0-py3-none-any.whl.metadata\n",
      "  Downloading keras_nlp-0.10.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Obtaining dependency information for keras-nlp from https://files.pythonhosted.org/packages/e6/2f/f5d6c74cbf870a901b03043e878c5dcaa5914c3a5e2656c233ba693be57d/keras_nlp-0.9.3-py3-none-any.whl.metadata\n",
      "  Downloading keras_nlp-0.9.3-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Obtaining dependency information for keras-nlp from https://files.pythonhosted.org/packages/c0/f8/fbeadb1bf5c12b00c358d68c2fbb7415f77f1d45491e23024a4b1f1b24a1/keras_nlp-0.9.2-py3-none-any.whl.metadata\n",
      "  Downloading keras_nlp-0.9.2-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Obtaining dependency information for keras-nlp from https://files.pythonhosted.org/packages/07/86/0cbb51fe39c4cf687f11b1dd4f5f220204c543911ed1fe497a2c0ce1cb1c/keras_nlp-0.9.1-py3-none-any.whl.metadata\n",
      "  Downloading keras_nlp-0.9.1-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Obtaining dependency information for keras-nlp from https://files.pythonhosted.org/packages/49/d4/e04a89ab3af9e83d45b93ac81b702995c1329c10aa974422b4a9229dc7d0/keras_nlp-0.9.0-py3-none-any.whl.metadata\n",
      "  Downloading keras_nlp-0.9.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Obtaining dependency information for keras-nlp from https://files.pythonhosted.org/packages/ce/fb/6248410ac2f035f8121e6dac0ac3bad5e2d10b92c99ff988f3ea08df47f2/keras_nlp-0.8.2-py3-none-any.whl.metadata\n",
      "  Downloading keras_nlp-0.8.2-py3-none-any.whl.metadata (7.0 kB)\n",
      "INFO: pip is still looking at multiple versions of keras-nlp to determine which version is compatible with other requirements. This could take a while.\n",
      "  Obtaining dependency information for keras-nlp from https://files.pythonhosted.org/packages/96/47/68284b9549cf92eb7be8b7b9948d05905c610cf9bdc082b3848c717ecd5e/keras_nlp-0.8.1-py3-none-any.whl.metadata\n",
      "  Downloading keras_nlp-0.8.1-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Obtaining dependency information for keras-nlp from https://files.pythonhosted.org/packages/a9/eb/a58c7b4e3568b5147584b52202cc0964aa9f9d50043381389efe3cfd23f2/keras_nlp-0.8.0-py3-none-any.whl.metadata\n",
      "  Downloading keras_nlp-0.8.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Obtaining dependency information for keras-nlp from https://files.pythonhosted.org/packages/26/9e/f9fed2d300df6b0fb4e04346bd928d178531fceb7507dbf757e771a0147c/keras_nlp-0.7.0-py3-none-any.whl.metadata\n",
      "  Downloading keras_nlp-0.7.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Obtaining dependency information for keras-nlp from https://files.pythonhosted.org/packages/29/bc/9fbc887eb5ec017dadbb339f5e80321fc1771ec8867f9ac8e869bc86f09a/keras_nlp-0.6.4-py3-none-any.whl.metadata\n",
      "  Downloading keras_nlp-0.6.4-py3-none-any.whl.metadata (8.5 kB)\n",
      "  Obtaining dependency information for keras-nlp from https://files.pythonhosted.org/packages/16/37/e2bdca1975d3e5ebafb63dfcddc3b55369e012763f63abd7699dae8c0a45/keras_nlp-0.6.3-py3-none-any.whl.metadata\n",
      "  Downloading keras_nlp-0.6.3-py3-none-any.whl.metadata (7.2 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Obtaining dependency information for keras-nlp from https://files.pythonhosted.org/packages/37/d4/dfd85606db811af2138e97fc480eb7ed709042dd96dd453868bede0929fe/keras_nlp-0.6.2-py3-none-any.whl.metadata\n",
      "  Downloading keras_nlp-0.6.2-py3-none-any.whl.metadata (7.2 kB)\n",
      "  Obtaining dependency information for keras-nlp from https://files.pythonhosted.org/packages/13/fc/258d2a78faaacceeaab2be1a64fbf69f77bd56d55758cd4188db3b0f71e3/keras_nlp-0.6.1-py3-none-any.whl.metadata\n",
      "  Downloading keras_nlp-0.6.1-py3-none-any.whl.metadata (7.2 kB)\n",
      "  Obtaining dependency information for keras-nlp from https://files.pythonhosted.org/packages/b6/43/31296dfcc9ed404f4449f9d99d54471c04122d0a183cd5b15df1fd189492/keras_nlp-0.6.0-py3-none-any.whl.metadata\n",
      "  Downloading keras_nlp-0.6.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "  Obtaining dependency information for keras-nlp from https://files.pythonhosted.org/packages/46/88/f8f6f5f6c2981f212b3a56d44e2523aee31b9d5cc3d8243b298068ed2aaa/keras_nlp-0.5.2-py3-none-any.whl.metadata\n",
      "  Downloading keras_nlp-0.5.2-py3-none-any.whl.metadata (5.7 kB)\n",
      "  Obtaining dependency information for keras-nlp from https://files.pythonhosted.org/packages/f0/44/856c1b54d347398e6148f4f3bfef7dc4040b4d6ec0cfb2b5b0e1c887bd44/keras_nlp-0.5.1-py3-none-any.whl.metadata\n",
      "  Downloading keras_nlp-0.5.1-py3-none-any.whl.metadata (5.7 kB)\n",
      "  Obtaining dependency information for keras-nlp from https://files.pythonhosted.org/packages/a1/71/bd924651af32e869617116f7af1250b27c1f1df2a802703a802569f339f6/keras_nlp-0.5.0-py3-none-any.whl.metadata\n",
      "  Downloading keras_nlp-0.5.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "  Obtaining dependency information for keras-nlp from https://files.pythonhosted.org/packages/67/41/b63bda303c882166800f7597a585dfb24f096bc7a748ff84546b78006524/keras_nlp-0.4.1-py3-none-any.whl.metadata\n",
      "  Downloading keras_nlp-0.4.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for keras-nlp from https://files.pythonhosted.org/packages/eb/90/991757e205e070fd169fb31e105f06be801ad04e8a35378bf1719fef2a22/keras_nlp-0.4.0-py3-none-any.whl.metadata\n",
      "  Downloading keras_nlp-0.4.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\bharg\\anaconda3\\lib\\site-packages (from keras-nlp) (2.16.1)\n",
      "  Obtaining dependency information for keras-nlp from https://files.pythonhosted.org/packages/3b/a6/ecaaf0cf26182108f4849ba444c431089c0e14641084fee4bc5d9e96088c/keras_nlp-0.3.1-py3-none-any.whl.metadata\n",
      "  Downloading keras_nlp-0.3.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "  Obtaining dependency information for keras-nlp from https://files.pythonhosted.org/packages/05/eb/d1a84fc539f806eba0a41491a6b896a80719603cd2821f7802098f3345f0/keras_nlp-0.3.0-py3-none-any.whl.metadata\n",
      "  Downloading keras_nlp-0.3.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "  Obtaining dependency information for keras-nlp from https://files.pythonhosted.org/packages/0a/ff/0d527353c0183b18cc53dcb080b46515e5efce62669662c45af5f91031b0/keras_nlp-0.2.0-py3-none-any.whl.metadata\n",
      "  Downloading keras_nlp-0.2.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "  Obtaining dependency information for keras-nlp from https://files.pythonhosted.org/packages/e8/47/e973480c2f82f64b9c14b29dcfe25c78ad071d9a2c4b99d8f802b118e6bd/keras_nlp-0.1.1-py3-none-any.whl.metadata\n",
      "  Downloading keras_nlp-0.1.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "  Obtaining dependency information for keras-nlp from https://files.pythonhosted.org/packages/4c/8d/5fb3e8acc6febe9ca4b877e2dc2c6544d92d096590a1fdaee357d94b6375/keras_nlp-0.1.0-py3-none-any.whl.metadata\n",
      "  Downloading keras_nlp-0.1.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "  Obtaining dependency information for keras-nlp from https://files.pythonhosted.org/packages/69/43/f11aa0569ee7126aedd3c805477b3412fed1d1a1d27e1cd5a518b93a74d0/keras_nlp-0.0.2-py3-none-any.whl.metadata\n",
      "  Downloading keras_nlp-0.0.2-py3-none-any.whl.metadata (712 bytes)\n",
      "Collecting tf-nightly (from keras-nlp)\n",
      "  Obtaining dependency information for tf-nightly from https://files.pythonhosted.org/packages/5f/e0/8d59f3d287041276fc98a92bd1bee213101ac332beca842aff397fb2c4d8/tf_nightly-2.17.0.dev20240509-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading tf_nightly-2.17.0.dev20240509-cp311-cp311-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tf-nightly-intel==2.17.0-dev20240509 (from tf-nightly->keras-nlp)\n",
      "  Obtaining dependency information for tf-nightly-intel==2.17.0-dev20240509 from https://files.pythonhosted.org/packages/e9/e9/f73f569135b0fcd9ef65c3890644f4d1b1bcc7e537cf7f9644d9d877906d/tf_nightly_intel-2.17.0.dev20240509-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading tf_nightly_intel-2.17.0.dev20240509-cp311-cp311-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\bharg\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.17.0-dev20240509->tf-nightly->keras-nlp) (1.6.3)\n",
      "Collecting flatbuffers>=24.3.25 (from tf-nightly-intel==2.17.0-dev20240509->tf-nightly->keras-nlp)\n",
      "  Obtaining dependency information for flatbuffers>=24.3.25 from https://files.pythonhosted.org/packages/41/f0/7e988a019bc54b2dbd0ad4182ef2d53488bb02e58694cd79d61369e85900/flatbuffers-24.3.25-py2.py3-none-any.whl.metadata\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\bharg\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.17.0-dev20240509->tf-nightly->keras-nlp) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\bharg\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.17.0-dev20240509->tf-nightly->keras-nlp) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\bharg\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.17.0-dev20240509->tf-nightly->keras-nlp) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\bharg\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.17.0-dev20240509->tf-nightly->keras-nlp) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\bharg\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.17.0-dev20240509->tf-nightly->keras-nlp) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\bharg\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.17.0-dev20240509->tf-nightly->keras-nlp) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\bharg\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.17.0-dev20240509->tf-nightly->keras-nlp) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\bharg\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.17.0-dev20240509->tf-nightly->keras-nlp) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\bharg\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.17.0-dev20240509->tf-nightly->keras-nlp) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\bharg\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.17.0-dev20240509->tf-nightly->keras-nlp) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\bharg\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.17.0-dev20240509->tf-nightly->keras-nlp) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\bharg\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.17.0-dev20240509->tf-nightly->keras-nlp) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\bharg\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.17.0-dev20240509->tf-nightly->keras-nlp) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\bharg\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.17.0-dev20240509->tf-nightly->keras-nlp) (1.62.1)\n",
      "Collecting tb-nightly~=2.17.0.a (from tf-nightly-intel==2.17.0-dev20240509->tf-nightly->keras-nlp)\n",
      "  Obtaining dependency information for tb-nightly~=2.17.0.a from https://files.pythonhosted.org/packages/44/a7/446ee1ae6bec36e0ed918fec0c42fbd75a6a83bab4703fb553afec83606c/tb_nightly-2.17.0a20240509-py3-none-any.whl.metadata\n",
      "  Downloading tb_nightly-2.17.0a20240509-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras-nightly>=3.2.0.dev (from tf-nightly-intel==2.17.0-dev20240509->tf-nightly->keras-nlp)\n",
      "  Obtaining dependency information for keras-nightly>=3.2.0.dev from https://files.pythonhosted.org/packages/be/b3/7b602ef35dcd094f9f12ed516b86c72b4452fe1100990ba62ac807cb824a/keras_nightly-3.3.3.dev2024050903-py3-none-any.whl.metadata\n",
      "  Downloading keras_nightly-3.3.3.dev2024050903-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\bharg\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.17.0-dev20240509->tf-nightly->keras-nlp) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\bharg\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tf-nightly-intel==2.17.0-dev20240509->tf-nightly->keras-nlp) (0.38.4)\n",
      "Requirement already satisfied: namex in c:\\users\\bharg\\anaconda3\\lib\\site-packages (from keras-nightly>=3.2.0.dev->tf-nightly-intel==2.17.0-dev20240509->tf-nightly->keras-nlp) (0.0.7)\n",
      "Collecting optree (from keras-nightly>=3.2.0.dev->tf-nightly-intel==2.17.0-dev20240509->tf-nightly->keras-nlp)\n",
      "  Obtaining dependency information for optree from https://files.pythonhosted.org/packages/8f/db/e05a35451d4ba30fdc65ef168dfdc68a6939ea6afdc0101e3e77f97e1547/optree-0.11.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading optree-0.11.0-cp311-cp311-win_amd64.whl.metadata (46 kB)\n",
      "     ---------------------------------------- 0.0/46.2 kB ? eta -:--:--\n",
      "     -------------------------- ------------- 30.7/46.2 kB 1.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- 46.2/46.2 kB 765.3 kB/s eta 0:00:00\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\bharg\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tf-nightly-intel==2.17.0-dev20240509->tf-nightly->keras-nlp) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bharg\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tf-nightly-intel==2.17.0-dev20240509->tf-nightly->keras-nlp) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\bharg\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tf-nightly-intel==2.17.0-dev20240509->tf-nightly->keras-nlp) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bharg\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tf-nightly-intel==2.17.0-dev20240509->tf-nightly->keras-nlp) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\bharg\\anaconda3\\lib\\site-packages (from tb-nightly~=2.17.0.a->tf-nightly-intel==2.17.0-dev20240509->tf-nightly->keras-nlp) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\bharg\\anaconda3\\lib\\site-packages (from tb-nightly~=2.17.0.a->tf-nightly-intel==2.17.0-dev20240509->tf-nightly->keras-nlp) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\bharg\\anaconda3\\lib\\site-packages (from tb-nightly~=2.17.0.a->tf-nightly-intel==2.17.0-dev20240509->tf-nightly->keras-nlp) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\bharg\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tb-nightly~=2.17.0.a->tf-nightly-intel==2.17.0-dev20240509->tf-nightly->keras-nlp) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\bharg\\anaconda3\\lib\\site-packages (from rich->keras-nlp) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\bharg\\anaconda3\\lib\\site-packages (from rich->keras-nlp) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\bharg\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras-nlp) (0.1.0)\n",
      "Downloading keras_nlp-0.0.2-py3-none-any.whl (23 kB)\n",
      "Downloading tf_nightly-2.17.0.dev20240509-cp311-cp311-win_amd64.whl (2.2 kB)\n",
      "Downloading tf_nightly_intel-2.17.0.dev20240509-cp311-cp311-win_amd64.whl (214.7 MB)\n",
      "   ---------------------------------------- 0.0/214.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/214.7 MB 3.8 MB/s eta 0:00:56\n",
      "   ---------------------------------------- 0.2/214.7 MB 2.8 MB/s eta 0:01:17\n",
      "   ---------------------------------------- 0.3/214.7 MB 2.9 MB/s eta 0:01:14\n",
      "   ---------------------------------------- 0.6/214.7 MB 4.5 MB/s eta 0:00:48\n",
      "   ---------------------------------------- 0.9/214.7 MB 4.8 MB/s eta 0:00:45\n",
      "   ---------------------------------------- 1.2/214.7 MB 4.9 MB/s eta 0:00:44\n",
      "   ---------------------------------------- 1.4/214.7 MB 5.4 MB/s eta 0:00:40\n",
      "   ---------------------------------------- 1.5/214.7 MB 4.8 MB/s eta 0:00:45\n",
      "   ---------------------------------------- 1.8/214.7 MB 4.9 MB/s eta 0:00:44\n",
      "   ---------------------------------------- 2.1/214.7 MB 5.3 MB/s eta 0:00:41\n",
      "   ---------------------------------------- 2.1/214.7 MB 5.3 MB/s eta 0:00:41\n",
      "   ---------------------------------------- 2.5/214.7 MB 5.3 MB/s eta 0:00:41\n",
      "   ---------------------------------------- 2.6/214.7 MB 5.1 MB/s eta 0:00:42\n",
      "    --------------------------------------- 2.9/214.7 MB 5.1 MB/s eta 0:00:42\n",
      "    --------------------------------------- 3.2/214.7 MB 5.3 MB/s eta 0:00:40\n",
      "    --------------------------------------- 3.3/214.7 MB 5.2 MB/s eta 0:00:41\n",
      "    --------------------------------------- 3.5/214.7 MB 5.1 MB/s eta 0:00:42\n",
      "    --------------------------------------- 3.7/214.7 MB 5.1 MB/s eta 0:00:42\n",
      "    --------------------------------------- 3.9/214.7 MB 5.1 MB/s eta 0:00:42\n",
      "    --------------------------------------- 4.1/214.7 MB 5.0 MB/s eta 0:00:43\n",
      "    --------------------------------------- 4.2/214.7 MB 4.9 MB/s eta 0:00:43\n",
      "    --------------------------------------- 4.4/214.7 MB 4.9 MB/s eta 0:00:43\n",
      "    --------------------------------------- 4.4/214.7 MB 4.8 MB/s eta 0:00:45\n",
      "    --------------------------------------- 4.5/214.7 MB 4.7 MB/s eta 0:00:46\n",
      "    --------------------------------------- 4.8/214.7 MB 4.7 MB/s eta 0:00:45\n",
      "    --------------------------------------- 5.1/214.7 MB 4.9 MB/s eta 0:00:43\n",
      "   - -------------------------------------- 5.4/214.7 MB 4.9 MB/s eta 0:00:44\n",
      "   - -------------------------------------- 5.8/214.7 MB 5.0 MB/s eta 0:00:42\n",
      "   - -------------------------------------- 5.9/214.7 MB 5.0 MB/s eta 0:00:42\n",
      "   - -------------------------------------- 6.3/214.7 MB 5.1 MB/s eta 0:00:41\n",
      "   - -------------------------------------- 6.6/214.7 MB 5.3 MB/s eta 0:00:40\n",
      "   - -------------------------------------- 6.9/214.7 MB 5.4 MB/s eta 0:00:39\n",
      "   - -------------------------------------- 7.3/214.7 MB 5.5 MB/s eta 0:00:38\n",
      "   - -------------------------------------- 7.5/214.7 MB 5.5 MB/s eta 0:00:38\n",
      "   - -------------------------------------- 7.9/214.7 MB 5.6 MB/s eta 0:00:37\n",
      "   - -------------------------------------- 8.0/214.7 MB 5.5 MB/s eta 0:00:38\n",
      "   - -------------------------------------- 8.2/214.7 MB 5.5 MB/s eta 0:00:38\n",
      "   - -------------------------------------- 8.4/214.7 MB 5.6 MB/s eta 0:00:38\n",
      "   - -------------------------------------- 8.8/214.7 MB 5.6 MB/s eta 0:00:37\n",
      "   - -------------------------------------- 9.1/214.7 MB 5.7 MB/s eta 0:00:37\n",
      "   - -------------------------------------- 9.5/214.7 MB 5.8 MB/s eta 0:00:36\n",
      "   - -------------------------------------- 9.9/214.7 MB 5.8 MB/s eta 0:00:36\n",
      "   - -------------------------------------- 10.2/214.7 MB 5.9 MB/s eta 0:00:35\n",
      "   - -------------------------------------- 10.5/214.7 MB 6.2 MB/s eta 0:00:34\n",
      "   - -------------------------------------- 10.6/214.7 MB 6.1 MB/s eta 0:00:34\n",
      "   - -------------------------------------- 10.6/214.7 MB 6.1 MB/s eta 0:00:34\n",
      "   -- ------------------------------------- 11.4/214.7 MB 6.1 MB/s eta 0:00:34\n",
      "   -- ------------------------------------- 11.5/214.7 MB 6.2 MB/s eta 0:00:33\n",
      "   -- ------------------------------------- 11.7/214.7 MB 6.0 MB/s eta 0:00:34\n",
      "   -- ------------------------------------- 11.9/214.7 MB 6.1 MB/s eta 0:00:34\n",
      "   -- ------------------------------------- 12.2/214.7 MB 6.1 MB/s eta 0:00:34\n",
      "   -- ------------------------------------- 12.4/214.7 MB 6.2 MB/s eta 0:00:33\n",
      "   -- ------------------------------------- 12.6/214.7 MB 6.1 MB/s eta 0:00:34\n",
      "   -- ------------------------------------- 12.8/214.7 MB 6.2 MB/s eta 0:00:33\n",
      "   -- ------------------------------------- 13.1/214.7 MB 6.2 MB/s eta 0:00:33\n",
      "   -- ------------------------------------- 13.5/214.7 MB 6.3 MB/s eta 0:00:32\n",
      "   -- ------------------------------------- 13.9/214.7 MB 6.4 MB/s eta 0:00:32\n",
      "   -- ------------------------------------- 14.2/214.7 MB 6.6 MB/s eta 0:00:31\n",
      "   -- ------------------------------------- 14.4/214.7 MB 6.8 MB/s eta 0:00:30\n",
      "   -- ------------------------------------- 14.8/214.7 MB 7.1 MB/s eta 0:00:29\n",
      "   -- ------------------------------------- 15.0/214.7 MB 7.2 MB/s eta 0:00:28\n",
      "   -- ------------------------------------- 15.4/214.7 MB 7.2 MB/s eta 0:00:28\n",
      "   -- ------------------------------------- 15.8/214.7 MB 7.2 MB/s eta 0:00:28\n",
      "   --- ------------------------------------ 16.1/214.7 MB 7.3 MB/s eta 0:00:28\n",
      "   --- ------------------------------------ 16.6/214.7 MB 7.3 MB/s eta 0:00:28\n",
      "   --- ------------------------------------ 16.9/214.7 MB 7.3 MB/s eta 0:00:28\n",
      "   --- ------------------------------------ 17.2/214.7 MB 7.2 MB/s eta 0:00:28\n",
      "   --- ------------------------------------ 17.5/214.7 MB 7.2 MB/s eta 0:00:28\n",
      "   --- ------------------------------------ 17.9/214.7 MB 7.2 MB/s eta 0:00:28\n",
      "   --- ------------------------------------ 18.3/214.7 MB 7.4 MB/s eta 0:00:27\n",
      "   --- ------------------------------------ 18.5/214.7 MB 7.4 MB/s eta 0:00:27\n",
      "   --- ------------------------------------ 18.9/214.7 MB 7.5 MB/s eta 0:00:27\n",
      "   --- ------------------------------------ 19.2/214.7 MB 7.4 MB/s eta 0:00:27\n",
      "   --- ------------------------------------ 19.5/214.7 MB 7.4 MB/s eta 0:00:27\n",
      "   --- ------------------------------------ 19.8/214.7 MB 7.4 MB/s eta 0:00:27\n",
      "   --- ------------------------------------ 19.9/214.7 MB 7.4 MB/s eta 0:00:27\n",
      "   --- ------------------------------------ 20.0/214.7 MB 7.2 MB/s eta 0:00:28\n",
      "   --- ------------------------------------ 20.0/214.7 MB 7.2 MB/s eta 0:00:28\n",
      "   --- ------------------------------------ 20.0/214.7 MB 7.2 MB/s eta 0:00:28\n",
      "   --- ------------------------------------ 20.0/214.7 MB 7.2 MB/s eta 0:00:28\n",
      "   --- ------------------------------------ 20.0/214.7 MB 7.2 MB/s eta 0:00:28\n",
      "   --- ------------------------------------ 20.0/214.7 MB 7.2 MB/s eta 0:00:28\n",
      "   --- ------------------------------------ 20.0/214.7 MB 7.2 MB/s eta 0:00:28\n",
      "   --- ------------------------------------ 20.0/214.7 MB 7.2 MB/s eta 0:00:28\n",
      "   --- ------------------------------------ 20.0/214.7 MB 7.2 MB/s eta 0:00:28\n",
      "   --- ------------------------------------ 20.0/214.7 MB 7.2 MB/s eta 0:00:28\n",
      "   --- ------------------------------------ 20.0/214.7 MB 7.2 MB/s eta 0:00:28\n",
      "   --- ------------------------------------ 20.4/214.7 MB 5.5 MB/s eta 0:00:36\n",
      "   --- ------------------------------------ 20.8/214.7 MB 5.6 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 21.3/214.7 MB 5.7 MB/s eta 0:00:34\n",
      "   --- ------------------------------------ 21.3/214.7 MB 5.8 MB/s eta 0:00:34\n",
      "   ---- ----------------------------------- 21.8/214.7 MB 5.6 MB/s eta 0:00:35\n",
      "   ---- ----------------------------------- 22.1/214.7 MB 5.9 MB/s eta 0:00:33\n",
      "   ---- ----------------------------------- 22.8/214.7 MB 6.1 MB/s eta 0:00:32\n",
      "   ---- ----------------------------------- 23.0/214.7 MB 6.2 MB/s eta 0:00:32\n",
      "   ---- ----------------------------------- 23.2/214.7 MB 6.1 MB/s eta 0:00:32\n",
      "   ---- ----------------------------------- 23.7/214.7 MB 6.1 MB/s eta 0:00:32\n",
      "   ---- ----------------------------------- 24.5/214.7 MB 6.3 MB/s eta 0:00:31\n",
      "   ---- ----------------------------------- 25.0/214.7 MB 6.4 MB/s eta 0:00:30\n",
      "   ---- ----------------------------------- 25.7/214.7 MB 6.5 MB/s eta 0:00:29\n",
      "   ---- ----------------------------------- 26.3/214.7 MB 6.8 MB/s eta 0:00:28\n",
      "   ----- ---------------------------------- 27.1/214.7 MB 7.0 MB/s eta 0:00:27\n",
      "   ----- ---------------------------------- 27.9/214.7 MB 7.4 MB/s eta 0:00:26\n",
      "   ----- ---------------------------------- 28.6/214.7 MB 7.6 MB/s eta 0:00:25\n",
      "   ----- ---------------------------------- 28.8/214.7 MB 7.6 MB/s eta 0:00:25\n",
      "   ----- ---------------------------------- 29.8/214.7 MB 8.1 MB/s eta 0:00:23\n",
      "   ----- ---------------------------------- 30.0/214.7 MB 8.0 MB/s eta 0:00:24\n",
      "   ----- ---------------------------------- 30.1/214.7 MB 8.0 MB/s eta 0:00:24\n",
      "   ----- ---------------------------------- 30.1/214.7 MB 8.0 MB/s eta 0:00:24\n",
      "   ----- ---------------------------------- 30.1/214.7 MB 8.0 MB/s eta 0:00:24\n",
      "   ----- ---------------------------------- 30.1/214.7 MB 8.0 MB/s eta 0:00:24\n",
      "   ----- ---------------------------------- 30.1/214.7 MB 8.0 MB/s eta 0:00:24\n",
      "   ----- ---------------------------------- 30.1/214.7 MB 8.0 MB/s eta 0:00:24\n",
      "   ----- ---------------------------------- 30.1/214.7 MB 8.0 MB/s eta 0:00:24\n",
      "   ----- ---------------------------------- 31.3/214.7 MB 9.8 MB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 31.5/214.7 MB 9.5 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 31.7/214.7 MB 9.8 MB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 32.1/214.7 MB 9.6 MB/s eta 0:00:19\n",
      "   ------ --------------------------------- 32.6/214.7 MB 9.6 MB/s eta 0:00:19\n",
      "   ------ --------------------------------- 32.6/214.7 MB 9.6 MB/s eta 0:00:19\n",
      "   ------ --------------------------------- 33.3/214.7 MB 9.8 MB/s eta 0:00:19\n",
      "   ------ --------------------------------- 33.4/214.7 MB 9.6 MB/s eta 0:00:19\n",
      "   ------ --------------------------------- 33.8/214.7 MB 9.5 MB/s eta 0:00:20\n",
      "   ------ --------------------------------- 34.1/214.7 MB 9.2 MB/s eta 0:00:20\n",
      "   ------ --------------------------------- 34.7/214.7 MB 9.4 MB/s eta 0:00:20\n",
      "   ------ --------------------------------- 35.0/214.7 MB 9.1 MB/s eta 0:00:20\n",
      "   ------ --------------------------------- 35.5/214.7 MB 9.0 MB/s eta 0:00:20\n",
      "   ------ --------------------------------- 36.2/214.7 MB 9.0 MB/s eta 0:00:20\n",
      "   ------ --------------------------------- 36.9/214.7 MB 9.0 MB/s eta 0:00:20\n",
      "   ------- -------------------------------- 37.7/214.7 MB 9.0 MB/s eta 0:00:20\n",
      "   ------- -------------------------------- 38.4/214.7 MB 9.0 MB/s eta 0:00:20\n",
      "   ------- -------------------------------- 39.0/214.7 MB 9.0 MB/s eta 0:00:20\n",
      "   ------- -------------------------------- 39.8/214.7 MB 9.1 MB/s eta 0:00:20\n",
      "   ------- -------------------------------- 40.5/214.7 MB 12.8 MB/s eta 0:00:14\n",
      "   ------- -------------------------------- 41.2/214.7 MB 12.4 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 42.0/214.7 MB 13.1 MB/s eta 0:00:14\n",
      "   ------- -------------------------------- 42.5/214.7 MB 13.6 MB/s eta 0:00:13\n",
      "   -------- ------------------------------- 43.3/214.7 MB 14.6 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 44.1/214.7 MB 15.6 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 44.6/214.7 MB 16.4 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 45.5/214.7 MB 17.2 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 46.3/214.7 MB 17.2 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 46.8/214.7 MB 17.7 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 47.6/214.7 MB 16.8 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 48.5/214.7 MB 16.8 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 49.3/214.7 MB 17.3 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 50.2/214.7 MB 17.2 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 50.8/214.7 MB 16.8 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 51.5/214.7 MB 16.8 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 52.3/214.7 MB 16.4 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 53.2/214.7 MB 16.8 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 53.9/214.7 MB 16.4 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 54.8/214.7 MB 16.4 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 55.7/214.7 MB 16.8 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 56.0/214.7 MB 16.4 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 57.0/214.7 MB 16.4 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 57.6/214.7 MB 16.4 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 58.4/214.7 MB 16.0 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 59.3/214.7 MB 16.0 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 60.0/214.7 MB 16.0 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 61.0/214.7 MB 16.4 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 61.7/214.7 MB 16.4 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 62.5/214.7 MB 16.4 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 63.3/214.7 MB 16.4 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 64.2/214.7 MB 16.8 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 65.1/214.7 MB 16.4 MB/s eta 0:00:10\n",
      "   ------------ --------------------------- 66.1/214.7 MB 16.4 MB/s eta 0:00:10\n",
      "   ------------ --------------------------- 67.0/214.7 MB 17.2 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 67.7/214.7 MB 17.7 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 68.6/214.7 MB 18.2 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 69.3/214.7 MB 17.7 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 70.1/214.7 MB 17.7 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 70.9/214.7 MB 17.7 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 71.5/214.7 MB 17.7 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 72.4/214.7 MB 17.3 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 73.2/214.7 MB 17.7 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 74.2/214.7 MB 18.2 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 74.9/214.7 MB 17.2 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 75.1/214.7 MB 16.8 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 75.8/214.7 MB 16.8 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 76.2/214.7 MB 16.0 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 76.2/214.7 MB 16.0 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 76.3/214.7 MB 14.6 MB/s eta 0:00:10\n",
      "   -------------- ------------------------- 76.7/214.7 MB 14.2 MB/s eta 0:00:10\n",
      "   -------------- ------------------------- 77.3/214.7 MB 13.6 MB/s eta 0:00:11\n",
      "   -------------- ------------------------- 77.9/214.7 MB 13.4 MB/s eta 0:00:11\n",
      "   -------------- ------------------------- 78.6/214.7 MB 13.4 MB/s eta 0:00:11\n",
      "   -------------- ------------------------- 78.9/214.7 MB 12.9 MB/s eta 0:00:11\n",
      "   -------------- ------------------------- 79.5/214.7 MB 12.6 MB/s eta 0:00:11\n",
      "   -------------- ------------------------- 80.5/214.7 MB 12.6 MB/s eta 0:00:11\n",
      "   --------------- ------------------------ 81.2/214.7 MB 12.6 MB/s eta 0:00:11\n",
      "   --------------- ------------------------ 82.0/214.7 MB 12.6 MB/s eta 0:00:11\n",
      "   --------------- ------------------------ 82.8/214.7 MB 12.8 MB/s eta 0:00:11\n",
      "   --------------- ------------------------ 83.5/214.7 MB 12.8 MB/s eta 0:00:11\n",
      "   --------------- ------------------------ 84.2/214.7 MB 12.8 MB/s eta 0:00:11\n",
      "   --------------- ------------------------ 84.8/214.7 MB 12.8 MB/s eta 0:00:11\n",
      "   --------------- ------------------------ 85.6/214.7 MB 13.6 MB/s eta 0:00:10\n",
      "   --------------- ------------------------ 85.6/214.7 MB 13.6 MB/s eta 0:00:10\n",
      "   --------------- ------------------------ 85.8/214.7 MB 12.3 MB/s eta 0:00:11\n",
      "   ---------------- ----------------------- 86.3/214.7 MB 12.1 MB/s eta 0:00:11\n",
      "   ---------------- ----------------------- 86.9/214.7 MB 13.9 MB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 87.6/214.7 MB 14.5 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 88.2/214.7 MB 15.2 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 89.1/214.7 MB 15.6 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 89.8/214.7 MB 16.0 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 90.2/214.7 MB 16.0 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 90.8/214.7 MB 15.2 MB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 91.4/214.7 MB 15.2 MB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 92.0/214.7 MB 14.6 MB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 92.6/214.7 MB 14.9 MB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 93.4/214.7 MB 14.9 MB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 93.9/214.7 MB 14.6 MB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 94.5/214.7 MB 14.6 MB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 95.2/214.7 MB 14.6 MB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 95.7/214.7 MB 14.2 MB/s eta 0:00:09\n",
      "   ------------------ --------------------- 96.7/214.7 MB 16.0 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 97.2/214.7 MB 16.0 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 98.1/214.7 MB 16.4 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 98.6/214.7 MB 16.0 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 99.1/214.7 MB 15.6 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 99.6/214.7 MB 16.0 MB/s eta 0:00:08\n",
      "   ------------------ -------------------- 100.5/214.7 MB 16.4 MB/s eta 0:00:07\n",
      "   ------------------ -------------------- 101.1/214.7 MB 16.4 MB/s eta 0:00:07\n",
      "   ------------------ -------------------- 101.9/214.7 MB 16.8 MB/s eta 0:00:07\n",
      "   ------------------ -------------------- 102.6/214.7 MB 16.4 MB/s eta 0:00:07\n",
      "   ------------------ -------------------- 103.3/214.7 MB 16.8 MB/s eta 0:00:07\n",
      "   ------------------ -------------------- 104.1/214.7 MB 16.8 MB/s eta 0:00:07\n",
      "   ------------------- ------------------- 104.7/214.7 MB 16.8 MB/s eta 0:00:07\n",
      "   ------------------- ------------------- 105.6/214.7 MB 17.2 MB/s eta 0:00:07\n",
      "   ------------------- ------------------- 106.3/214.7 MB 17.7 MB/s eta 0:00:07\n",
      "   ------------------- ------------------- 107.1/214.7 MB 17.7 MB/s eta 0:00:07\n",
      "   ------------------- ------------------- 107.8/214.7 MB 17.7 MB/s eta 0:00:07\n",
      "   ------------------- ------------------- 108.8/214.7 MB 17.7 MB/s eta 0:00:06\n",
      "   ------------------- ------------------- 109.4/214.7 MB 17.7 MB/s eta 0:00:06\n",
      "   ------------------- ------------------- 109.5/214.7 MB 16.8 MB/s eta 0:00:07\n",
      "   ------------------- ------------------- 109.9/214.7 MB 16.4 MB/s eta 0:00:07\n",
      "   -------------------- ------------------ 110.6/214.7 MB 16.0 MB/s eta 0:00:07\n",
      "   -------------------- ------------------ 111.3/214.7 MB 16.4 MB/s eta 0:00:07\n",
      "   -------------------- ------------------ 112.1/214.7 MB 16.4 MB/s eta 0:00:07\n",
      "   -------------------- ------------------ 112.9/214.7 MB 16.8 MB/s eta 0:00:07\n",
      "   -------------------- ------------------ 113.4/214.7 MB 16.4 MB/s eta 0:00:07\n",
      "   -------------------- ------------------ 114.3/214.7 MB 16.4 MB/s eta 0:00:07\n",
      "   -------------------- ------------------ 114.7/214.7 MB 16.0 MB/s eta 0:00:07\n",
      "   -------------------- ------------------ 115.6/214.7 MB 16.0 MB/s eta 0:00:07\n",
      "   --------------------- ----------------- 116.3/214.7 MB 16.0 MB/s eta 0:00:07\n",
      "   --------------------- ----------------- 117.1/214.7 MB 16.0 MB/s eta 0:00:07\n",
      "   --------------------- ----------------- 117.9/214.7 MB 16.0 MB/s eta 0:00:07\n",
      "   --------------------- ----------------- 118.4/214.7 MB 16.0 MB/s eta 0:00:07\n",
      "   --------------------- ----------------- 119.3/214.7 MB 16.4 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 119.9/214.7 MB 17.7 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 120.6/214.7 MB 17.7 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 121.3/214.7 MB 17.7 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 122.2/214.7 MB 17.7 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 123.0/214.7 MB 17.7 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 123.8/214.7 MB 19.3 MB/s eta 0:00:05\n",
      "   ---------------------- ---------------- 124.5/214.7 MB 18.2 MB/s eta 0:00:05\n",
      "   ---------------------- ---------------- 125.1/214.7 MB 18.7 MB/s eta 0:00:05\n",
      "   ---------------------- ---------------- 126.0/214.7 MB 18.7 MB/s eta 0:00:05\n",
      "   ---------------------- ---------------- 126.6/214.7 MB 18.2 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 127.4/214.7 MB 18.7 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 128.3/214.7 MB 18.7 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 129.0/214.7 MB 18.2 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 129.7/214.7 MB 18.7 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 130.5/214.7 MB 18.7 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 131.1/214.7 MB 18.7 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 131.4/214.7 MB 17.7 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 132.1/214.7 MB 17.2 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 132.9/214.7 MB 16.8 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 133.8/214.7 MB 17.2 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 134.7/214.7 MB 17.2 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 135.6/214.7 MB 17.7 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 136.4/214.7 MB 17.2 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 137.1/214.7 MB 16.8 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 137.4/214.7 MB 16.4 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 137.9/214.7 MB 15.2 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 138.5/214.7 MB 15.2 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 138.6/214.7 MB 14.6 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 139.5/214.7 MB 14.6 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 139.7/214.7 MB 13.4 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 140.5/214.7 MB 13.6 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 140.5/214.7 MB 13.6 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 140.5/214.7 MB 13.6 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 140.5/214.7 MB 13.6 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 140.5/214.7 MB 13.6 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 140.5/214.7 MB 13.6 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 140.5/214.7 MB 10.1 MB/s eta 0:00:08\n",
      "   ------------------------- ------------- 140.5/214.7 MB 10.1 MB/s eta 0:00:08\n",
      "   ------------------------- ------------- 140.5/214.7 MB 10.1 MB/s eta 0:00:08\n",
      "   ------------------------- ------------- 140.5/214.7 MB 10.1 MB/s eta 0:00:08\n",
      "   ------------------------- ------------- 140.5/214.7 MB 10.1 MB/s eta 0:00:08\n",
      "   ------------------------- ------------- 140.5/214.7 MB 10.1 MB/s eta 0:00:08\n",
      "   -------------------------- ------------- 141.5/214.7 MB 8.5 MB/s eta 0:00:09\n",
      "   -------------------------- ------------- 141.7/214.7 MB 8.4 MB/s eta 0:00:09\n",
      "   -------------------------- ------------- 142.0/214.7 MB 8.1 MB/s eta 0:00:09\n",
      "   -------------------------- ------------- 142.2/214.7 MB 7.8 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 142.4/214.7 MB 7.6 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 142.6/214.7 MB 7.4 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 142.7/214.7 MB 7.4 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 143.2/214.7 MB 7.0 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 143.5/214.7 MB 7.0 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 143.8/214.7 MB 6.8 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 143.9/214.7 MB 6.6 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 144.2/214.7 MB 6.5 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 144.4/214.7 MB 6.3 MB/s eta 0:00:12\n",
      "   -------------------------- ------------- 144.7/214.7 MB 6.2 MB/s eta 0:00:12\n",
      "   -------------------------- ------------- 144.8/214.7 MB 6.1 MB/s eta 0:00:12\n",
      "   --------------------------- ------------ 145.0/214.7 MB 5.9 MB/s eta 0:00:12\n",
      "   --------------------------- ------------ 145.2/214.7 MB 5.8 MB/s eta 0:00:13\n",
      "   --------------------------- ------------ 145.4/214.7 MB 5.7 MB/s eta 0:00:13\n",
      "   --------------------------- ------------ 145.5/214.7 MB 5.6 MB/s eta 0:00:13\n",
      "   --------------------------- ------------ 145.6/214.7 MB 5.6 MB/s eta 0:00:13\n",
      "   --------------------------- ------------ 146.0/214.7 MB 5.4 MB/s eta 0:00:13\n",
      "   --------------------------- ------------ 146.2/214.7 MB 5.2 MB/s eta 0:00:14\n",
      "   --------------------------- ------------ 146.3/214.7 MB 5.2 MB/s eta 0:00:14\n",
      "   --------------------------- ------------ 146.6/214.7 MB 5.0 MB/s eta 0:00:14\n",
      "   --------------------------- ------------ 146.8/214.7 MB 5.0 MB/s eta 0:00:14\n",
      "   --------------------------- ------------ 147.0/214.7 MB 4.9 MB/s eta 0:00:14\n",
      "   --------------------------- ------------ 147.2/214.7 MB 4.8 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 147.5/214.7 MB 4.7 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 147.7/214.7 MB 4.7 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 147.8/214.7 MB 4.7 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 148.1/214.7 MB 4.6 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 148.4/214.7 MB 4.6 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 148.6/214.7 MB 4.5 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 148.8/214.7 MB 4.5 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 149.0/214.7 MB 4.5 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 149.2/214.7 MB 4.5 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 149.4/214.7 MB 4.4 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 149.5/214.7 MB 4.3 MB/s eta 0:00:16\n",
      "   --------------------------- ------------ 149.8/214.7 MB 4.2 MB/s eta 0:00:16\n",
      "   --------------------------- ------------ 150.0/214.7 MB 4.2 MB/s eta 0:00:16\n",
      "   --------------------------- ------------ 150.2/214.7 MB 4.1 MB/s eta 0:00:16\n",
      "   ---------------------------- ----------- 150.4/214.7 MB 4.1 MB/s eta 0:00:16\n",
      "   ---------------------------- ----------- 150.7/214.7 MB 4.0 MB/s eta 0:00:16\n",
      "   ---------------------------- ----------- 150.9/214.7 MB 5.0 MB/s eta 0:00:13\n",
      "   ---------------------------- ----------- 151.2/214.7 MB 4.9 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 151.4/214.7 MB 4.8 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 151.9/214.7 MB 4.7 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 152.2/214.7 MB 4.8 MB/s eta 0:00:13\n",
      "   ---------------------------- ----------- 152.7/214.7 MB 4.9 MB/s eta 0:00:13\n",
      "   ---------------------------- ----------- 153.0/214.7 MB 5.0 MB/s eta 0:00:13\n",
      "   ---------------------------- ----------- 153.3/214.7 MB 5.0 MB/s eta 0:00:13\n",
      "   ---------------------------- ----------- 153.7/214.7 MB 5.1 MB/s eta 0:00:13\n",
      "   ---------------------------- ----------- 154.1/214.7 MB 5.2 MB/s eta 0:00:12\n",
      "   ---------------------------- ----------- 154.5/214.7 MB 5.2 MB/s eta 0:00:12\n",
      "   ---------------------------- ----------- 154.9/214.7 MB 5.3 MB/s eta 0:00:12\n",
      "   ---------------------------- ----------- 155.3/214.7 MB 5.5 MB/s eta 0:00:11\n",
      "   ---------------------------- ----------- 155.7/214.7 MB 5.6 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 156.0/214.7 MB 5.8 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 156.4/214.7 MB 5.8 MB/s eta 0:00:10\n",
      "   ----------------------------- ---------- 156.8/214.7 MB 6.1 MB/s eta 0:00:10\n",
      "   ----------------------------- ---------- 157.1/214.7 MB 6.2 MB/s eta 0:00:10\n",
      "   ----------------------------- ---------- 157.1/214.7 MB 6.1 MB/s eta 0:00:10\n",
      "   ----------------------------- ---------- 157.5/214.7 MB 6.2 MB/s eta 0:00:10\n",
      "   ----------------------------- ---------- 157.8/214.7 MB 6.2 MB/s eta 0:00:10\n",
      "   ----------------------------- ---------- 158.1/214.7 MB 6.4 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 158.5/214.7 MB 6.3 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 158.9/214.7 MB 6.4 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 159.3/214.7 MB 6.6 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 159.6/214.7 MB 6.8 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 160.1/214.7 MB 7.1 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 160.5/214.7 MB 7.4 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 160.9/214.7 MB 7.6 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 161.5/214.7 MB 7.9 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 161.9/214.7 MB 8.2 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 162.1/214.7 MB 7.9 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 162.5/214.7 MB 7.9 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 162.7/214.7 MB 7.7 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 163.0/214.7 MB 7.7 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 163.3/214.7 MB 7.6 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 163.6/214.7 MB 7.5 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 164.0/214.7 MB 7.5 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 164.3/214.7 MB 7.5 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 164.5/214.7 MB 7.4 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 164.8/214.7 MB 7.4 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 165.0/214.7 MB 7.1 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 165.4/214.7 MB 7.1 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 165.6/214.7 MB 7.1 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 165.8/214.7 MB 7.0 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 165.9/214.7 MB 6.8 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 166.2/214.7 MB 6.7 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 166.4/214.7 MB 6.7 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 166.6/214.7 MB 6.7 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 166.7/214.7 MB 6.5 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 167.0/214.7 MB 6.4 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 167.3/214.7 MB 6.3 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 167.7/214.7 MB 6.5 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 168.2/214.7 MB 6.7 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 168.7/214.7 MB 6.8 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 169.0/214.7 MB 6.8 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 169.4/214.7 MB 6.8 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 169.8/214.7 MB 6.8 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 170.2/214.7 MB 6.7 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 170.5/214.7 MB 6.7 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 170.9/214.7 MB 6.7 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 171.4/214.7 MB 6.7 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 171.8/214.7 MB 6.6 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 172.2/214.7 MB 6.7 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 172.6/214.7 MB 6.8 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 173.0/214.7 MB 6.8 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 173.3/214.7 MB 6.7 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 173.7/214.7 MB 6.8 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 174.1/214.7 MB 6.9 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 174.5/214.7 MB 6.9 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 174.8/214.7 MB 7.0 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 175.1/214.7 MB 7.0 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 175.4/214.7 MB 7.1 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 175.7/214.7 MB 7.0 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 176.1/214.7 MB 7.4 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 176.5/214.7 MB 7.4 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 176.7/214.7 MB 7.5 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 177.1/214.7 MB 7.8 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 177.5/214.7 MB 8.0 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 178.0/214.7 MB 8.0 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 178.4/214.7 MB 8.0 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 178.8/214.7 MB 7.8 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 179.1/214.7 MB 7.8 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 179.4/214.7 MB 7.8 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 179.8/214.7 MB 7.8 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 180.2/214.7 MB 7.8 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 180.6/214.7 MB 7.9 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 180.9/214.7 MB 7.9 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 181.3/214.7 MB 7.7 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 181.6/214.7 MB 7.7 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 182.1/214.7 MB 7.7 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 182.3/214.7 MB 7.6 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 182.7/214.7 MB 7.6 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 182.8/214.7 MB 7.5 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 183.0/214.7 MB 7.3 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 183.4/214.7 MB 7.4 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 183.9/214.7 MB 7.4 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 184.4/214.7 MB 7.4 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 184.5/214.7 MB 7.4 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 185.1/214.7 MB 7.4 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 185.4/214.7 MB 7.4 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 185.8/214.7 MB 7.4 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 186.1/214.7 MB 7.4 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 186.4/214.7 MB 7.5 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 186.8/214.7 MB 7.4 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 187.3/214.7 MB 7.7 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 187.6/214.7 MB 7.6 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 187.9/214.7 MB 7.4 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 188.4/214.7 MB 7.4 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 188.8/214.7 MB 7.5 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 189.2/214.7 MB 7.6 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 189.5/214.7 MB 7.5 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 189.8/214.7 MB 7.5 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 190.0/214.7 MB 7.5 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 190.5/214.7 MB 7.5 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 191.0/214.7 MB 7.6 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 191.3/214.7 MB 7.6 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 191.7/214.7 MB 7.6 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 192.0/214.7 MB 7.7 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 192.0/214.7 MB 7.6 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 192.6/214.7 MB 7.6 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 193.0/214.7 MB 7.5 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 193.3/214.7 MB 7.8 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 193.7/214.7 MB 7.7 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 194.2/214.7 MB 7.7 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 194.6/214.7 MB 7.8 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 195.0/214.7 MB 7.8 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 195.4/214.7 MB 7.9 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 195.7/214.7 MB 7.9 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 196.1/214.7 MB 7.8 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 196.6/214.7 MB 8.0 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 197.0/214.7 MB 8.1 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 197.3/214.7 MB 7.9 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 197.7/214.7 MB 8.0 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 198.0/214.7 MB 8.0 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 198.3/214.7 MB 8.0 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 198.7/214.7 MB 8.0 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 199.3/214.7 MB 8.1 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 199.8/214.7 MB 8.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 200.2/214.7 MB 8.3 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 200.6/214.7 MB 8.4 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 201.2/214.7 MB 8.4 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 201.6/214.7 MB 8.5 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 202.1/214.7 MB 8.6 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 202.4/214.7 MB 9.0 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 202.8/214.7 MB 8.6 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 203.2/214.7 MB 8.7 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 203.5/214.7 MB 8.7 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 203.7/214.7 MB 8.5 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 204.3/214.7 MB 8.7 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 204.6/214.7 MB 8.7 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 205.0/214.7 MB 8.6 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 205.4/214.7 MB 8.5 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 205.7/214.7 MB 8.6 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 206.0/214.7 MB 8.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 206.3/214.7 MB 8.2 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 206.5/214.7 MB 8.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 206.6/214.7 MB 8.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 207.3/214.7 MB 8.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 207.6/214.7 MB 8.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 207.9/214.7 MB 8.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 208.2/214.7 MB 8.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 208.5/214.7 MB 8.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 208.9/214.7 MB 7.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 209.3/214.7 MB 8.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  209.7/214.7 MB 7.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  210.1/214.7 MB 7.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  210.4/214.7 MB 7.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  210.9/214.7 MB 7.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  211.1/214.7 MB 7.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  211.7/214.7 MB 7.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  211.7/214.7 MB 7.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  212.3/214.7 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  212.8/214.7 MB 7.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  213.2/214.7 MB 7.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  213.5/214.7 MB 7.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  213.7/214.7 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  214.1/214.7 MB 7.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  214.6/214.7 MB 7.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  214.7/214.7 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  214.7/214.7 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  214.7/214.7 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  214.7/214.7 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  214.7/214.7 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  214.7/214.7 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  214.7/214.7 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  214.7/214.7 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  214.7/214.7 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  214.7/214.7 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 214.7/214.7 MB 4.7 MB/s eta 0:00:00\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading keras_nightly-3.3.3.dev2024050903-py3-none-any.whl (1.1 MB)\n",
      "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.3/1.1 MB 5.9 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 0.7/1.1 MB 7.0 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 0.7/1.1 MB 7.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.1/1.1 MB 6.5 MB/s eta 0:00:00\n",
      "Downloading tb_nightly-2.17.0a20240509-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.3/5.5 MB 10.2 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 0.7/5.5 MB 8.7 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 1.0/5.5 MB 7.9 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 1.3/5.5 MB 8.3 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 1.9/5.5 MB 8.5 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 2.3/5.5 MB 8.6 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 2.7/5.5 MB 8.6 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 3.0/5.5 MB 8.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 3.3/5.5 MB 8.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 3.6/5.5 MB 8.0 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 3.7/5.5 MB 7.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 3.8/5.5 MB 6.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 4.0/5.5 MB 6.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 4.1/5.5 MB 6.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 4.4/5.5 MB 6.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 4.5/5.5 MB 6.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 4.5/5.5 MB 6.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 4.5/5.5 MB 6.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 4.5/5.5 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.5/5.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 5.8 MB/s eta 0:00:00\n",
      "Downloading optree-0.11.0-cp311-cp311-win_amd64.whl (245 kB)\n",
      "   ---------------------------------------- 0.0/245.0 kB ? eta -:--:--\n",
      "   ---------------- ----------------------- 102.4/245.0 kB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 245.0/245.0 kB 3.0 MB/s eta 0:00:00\n",
      "Installing collected packages: flatbuffers, optree, tb-nightly, keras-nightly, tf-nightly-intel, tf-nightly, keras-nlp\n",
      "  Attempting uninstall: flatbuffers\n",
      "    Found existing installation: flatbuffers 24.3.7\n",
      "    Uninstalling flatbuffers-24.3.7:\n",
      "      Successfully uninstalled flatbuffers-24.3.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\bharg\\\\anaconda3\\\\Lib\\\\site-packages\\\\tensorflow\\\\compiler\\\\mlir\\\\quantization\\\\tensorflow\\\\python\\\\pywrap_function_lib.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install keras-nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7d61ca-42d5-4de1-8ddf-34de3c44bb4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
